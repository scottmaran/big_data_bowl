{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "7392d46f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import json\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e343dee6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "id": "76574a81",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create model\n",
    "\n",
    "'''\n",
    "Actor\n",
    "Input: states\n",
    "Output: action \n",
    "'''\n",
    "class Actor(nn.Module):\n",
    "    def __init__(self, state_size, action_size):\n",
    "        super(Actor, self).__init__()\n",
    "        self.state_size = state_size\n",
    "        self.action_size = action_size\n",
    "        \n",
    "        self.linear1 = nn.Linear(state_size, 128)\n",
    "        self.linear2 = nn.Linear(128, 256)\n",
    "        self.linear3 = nn.Linear(256, action_size)\n",
    "        \n",
    "        self.relu = nn.ReLU()\n",
    "        \n",
    "    def forward(self, state):\n",
    "        \n",
    "        lay_out = self.linear1(state)\n",
    "        layer1_output = self.relu(lay_out)\n",
    "        layer2_output = self.relu(self.linear2(layer1_output))\n",
    "        output = self.relu(self.linear3(layer2_output))\n",
    "        \n",
    "        return output\n",
    "\n",
    "    \n",
    "'''\n",
    "Critic\n",
    "Input: state, action pair\n",
    "Output: (value)\n",
    "'''\n",
    "class Critic(nn.Module):\n",
    "    def __init__(self, state_size, action_size):\n",
    "        super(Critic, self).__init__()\n",
    "        self.state_size = state_size\n",
    "        self.action_size = action_size\n",
    "        \n",
    "        self.linear1 = nn.Linear(state_size+action_size, 128)\n",
    "        self.linear2 = nn.Linear(128, 256)\n",
    "        self.linear3 = nn.Linear(256, 1)\n",
    "        \n",
    "        self.relu = nn.ReLU()\n",
    "        \n",
    "    def forward(self, inp):\n",
    "        \n",
    "        layer1_output = self.relu(self.linear1(inp))\n",
    "        layer2_output = self.relu(self.linear2(layer1_output))\n",
    "        output = self.relu(self.linear3(layer2_output))\n",
    "        \n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "8fefa311",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>playIndex</th>\n",
       "      <th>timeIndex</th>\n",
       "      <th>state</th>\n",
       "      <th>next_state</th>\n",
       "      <th>reward</th>\n",
       "      <th>action</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>48</td>\n",
       "      <td>[11.4, 42.67, 55.74, 36.49, 47.81, 23.35, 47.3...</td>\n",
       "      <td>[11.39, 42.66, 55.07, 36.68, 46.88, 23.75, 46....</td>\n",
       "      <td>0.01</td>\n",
       "      <td>[0.01, 0.01]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>49</td>\n",
       "      <td>[11.39, 42.66, 55.07, 36.68, 46.88, 23.75, 46....</td>\n",
       "      <td>[11.41, 42.63, 54.4, 36.86, 45.96, 24.14, 45.6...</td>\n",
       "      <td>0.04</td>\n",
       "      <td>[-0.02, 0.03]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>50</td>\n",
       "      <td>[11.41, 42.63, 54.4, 36.86, 45.96, 24.14, 45.6...</td>\n",
       "      <td>[11.45, 42.56, 53.73, 37.04, 45.04, 24.53, 44....</td>\n",
       "      <td>0.08</td>\n",
       "      <td>[-0.04, 0.07]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>51</td>\n",
       "      <td>[11.45, 42.56, 53.73, 37.04, 45.04, 24.53, 44....</td>\n",
       "      <td>[11.53, 42.45, 53.07, 37.21, 44.11, 24.92, 43....</td>\n",
       "      <td>0.14</td>\n",
       "      <td>[-0.08, 0.11]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>52</td>\n",
       "      <td>[11.53, 42.45, 53.07, 37.21, 44.11, 24.92, 43....</td>\n",
       "      <td>[11.62, 42.32, 52.41, 37.37, 43.17, 25.29, 43....</td>\n",
       "      <td>0.16</td>\n",
       "      <td>[-0.09, 0.13]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   playIndex  timeIndex                                              state  \\\n",
       "0          0         48  [11.4, 42.67, 55.74, 36.49, 47.81, 23.35, 47.3...   \n",
       "1          0         49  [11.39, 42.66, 55.07, 36.68, 46.88, 23.75, 46....   \n",
       "2          0         50  [11.41, 42.63, 54.4, 36.86, 45.96, 24.14, 45.6...   \n",
       "3          0         51  [11.45, 42.56, 53.73, 37.04, 45.04, 24.53, 44....   \n",
       "4          0         52  [11.53, 42.45, 53.07, 37.21, 44.11, 24.92, 43....   \n",
       "\n",
       "                                          next_state  reward         action  \n",
       "0  [11.39, 42.66, 55.07, 36.68, 46.88, 23.75, 46....    0.01   [0.01, 0.01]  \n",
       "1  [11.41, 42.63, 54.4, 36.86, 45.96, 24.14, 45.6...    0.04  [-0.02, 0.03]  \n",
       "2  [11.45, 42.56, 53.73, 37.04, 45.04, 24.53, 44....    0.08  [-0.04, 0.07]  \n",
       "3  [11.53, 42.45, 53.07, 37.21, 44.11, 24.92, 43....    0.14  [-0.08, 0.11]  \n",
       "4  [11.62, 42.32, 52.41, 37.37, 43.17, 25.29, 43....    0.16  [-0.09, 0.13]  "
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Don't need buffer because have all states\n",
    "import ast\n",
    "\n",
    "def from_np_array(array_string):\n",
    "    array_string = ','.join(array_string.replace('[ ', '[').split())\n",
    "    index = 0\n",
    "    #array_string = ','.join(array_string.replace('\\n', ' ').split())\n",
    "    try:\n",
    "        return np.array(ast.literal_eval(array_string))\n",
    "    except:\n",
    "        index += 1\n",
    "\n",
    "\n",
    "df = pd.read_csv(\"all_players.csv\", index_col=0, converters={'state':from_np_array, 'next_state':from_np_array, 'action':from_np_array})\n",
    "\n",
    "df.head()\n",
    "\n",
    "#from_np_array(df['state'][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "551ec320",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "8c7a7501",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "id": "f95767cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "State size: 46\n"
     ]
    }
   ],
   "source": [
    "# define hyperparameters\n",
    "iterations = 10000\n",
    "state_size = len(df.loc[0,'state'])\n",
    "action_size = 2\n",
    "gamma = 0.99\n",
    "\n",
    "# create models\n",
    "critic = Critic(state_size, action_size)\n",
    "actor = Actor(state_size, action_size)\n",
    "critic_target = critic\n",
    "actor_target = actor\n",
    "\n",
    "# define loss function\n",
    "critic_loss_function = nn.MSELoss()\n",
    "# define optimizers\n",
    "actor_optimizer = optim.Adam(actor.parameters())\n",
    "critic_optimizer = optim.Adam(critic.parameters())\n",
    "\n",
    "print(f\"State size: {state_size}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "id": "0ef886c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# return batch_size of plays\n",
    "def sample_from_plays(batch_size, df):\n",
    "    \n",
    "    indices = np.random.choice(len(df), batch_size, replace=False)\n",
    "    \n",
    "    plays = df.iloc[indices, :]\n",
    "    \n",
    "    return plays\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "id": "2afcb0dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 88.2000,   4.6300,  84.4500,   6.4400,  82.7200,  14.6000,  87.4600,\n",
      "           4.1400,  91.2100,  16.9700,  84.9500,  18.2500,  87.3600,  21.5200,\n",
      "          89.0500,  15.4500,  64.7300,  12.2100,  74.0600,  27.6600,  88.8400,\n",
      "          13.4600,  88.0400,   6.0000,  88.6000,  22.1000,  87.9500,   7.1700,\n",
      "          87.3100,   5.5000,  89.7500,  13.2300,  84.8300,   7.1400,  89.0600,\n",
      "          19.7400,  92.1000,  22.9200,  82.8900,   6.9900,  88.8600,   6.9700,\n",
      "          88.8600,   9.5400,  88.1400,   4.6600],\n",
      "        [102.2200,  13.6100,  66.9300,  19.8600,  80.6100,  19.3300,  84.1500,\n",
      "          28.1300,  83.7600,   8.2300,  83.6500,  16.9700,  82.7500,  21.3900,\n",
      "          84.4700,  35.4800,  78.6300,   9.7200,  82.0200,  12.1900,  82.7500,\n",
      "          10.5500,  86.0800,  24.4400,  75.7200,  19.4500,  85.6500,  33.7300,\n",
      "          83.1700,  21.9400,  84.8100,  17.4000,  88.8100,  10.3300,  85.1000,\n",
      "          12.2300,  87.3000,  24.1100,  82.9300,  18.6300,  82.9200,  18.2300,\n",
      "          88.4000,  26.2800, 101.8800,  13.2400]], dtype=torch.float64)\n",
      "################\n",
      "tensor([[ 88.2000,   4.6300,  84.4500,   6.4400,  82.7200,  14.6000,  87.4600,\n",
      "           4.1400,  91.2100,  16.9700,  84.9500,  18.2500,  87.3600,  21.5200,\n",
      "          89.0500,  15.4500,  64.7300,  12.2100,  74.0600,  27.6600,  88.8400,\n",
      "          13.4600,  88.0400,   6.0000,  88.6000,  22.1000,  87.9500,   7.1700,\n",
      "          87.3100,   5.5000,  89.7500,  13.2300,  84.8300,   7.1400,  89.0600,\n",
      "          19.7400,  92.1000,  22.9200,  82.8900,   6.9900,  88.8600,   6.9700,\n",
      "          88.8600,   9.5400,  88.1400,   4.6600],\n",
      "        [102.2200,  13.6100,  66.9300,  19.8600,  80.6100,  19.3300,  84.1500,\n",
      "          28.1300,  83.7600,   8.2300,  83.6500,  16.9700,  82.7500,  21.3900,\n",
      "          84.4700,  35.4800,  78.6300,   9.7200,  82.0200,  12.1900,  82.7500,\n",
      "          10.5500,  86.0800,  24.4400,  75.7200,  19.4500,  85.6500,  33.7300,\n",
      "          83.1700,  21.9400,  84.8100,  17.4000,  88.8100,  10.3300,  85.1000,\n",
      "          12.2300,  87.3000,  24.1100,  82.9300,  18.6300,  82.9200,  18.2300,\n",
      "          88.4000,  26.2800, 101.8800,  13.2400]])\n",
      "tensor([[ 87.7600,   4.2200,  84.8100,   6.3300,  82.9900,  14.1900,  87.8600,\n",
      "           3.9700,  91.0500,  16.6700,  84.8900,  17.7300,  86.9900,  21.1500,\n",
      "          88.5800,  15.1500,  65.1800,  11.8200,  74.3800,  27.5800,  88.8900,\n",
      "          13.2700,  87.9000,   5.4900,  88.7500,  21.6800,  88.0300,   6.6300,\n",
      "          87.0200,   5.0600,  89.8100,  12.9200,  84.7200,   6.7100,  89.5600,\n",
      "          19.5800,  91.7800,  22.7200,  83.1900,   6.4800,  88.7700,   6.4000,\n",
      "          88.3000,   9.1800,  87.6800,   4.3200],\n",
      "        [101.5400,  13.3900,  67.4200,  19.5500,  80.3200,  19.0300,  84.6300,\n",
      "          27.6300,  84.3300,   8.2800,  83.9700,  16.8400,  83.2400,  20.8500,\n",
      "          84.8900,  35.0700,  79.1400,   9.7700,  82.2900,  12.4300,  83.2700,\n",
      "          10.5600,  86.4900,  23.8400,  75.8100,  19.1100,  85.8800,  33.6900,\n",
      "          83.4400,  21.4500,  85.2600,  17.4000,  88.4700,  10.1300,  85.2600,\n",
      "          12.0700,  87.3600,  23.7100,  83.1700,  18.6600,  83.1800,  18.2100,\n",
      "          88.1000,  26.0400, 101.2400,  12.9900]])\n",
      "tensor([0.6000, 0.7100], dtype=torch.float64)\n",
      "tensor([[0.4400, 0.4100],\n",
      "        [0.6800, 0.2200]])\n",
      "####################\n",
      "torch.Size([2, 46])\n",
      "torch.Size([2, 2])\n",
      "tensor([[ 88.2000,   4.6300,  84.4500,   6.4400,  82.7200,  14.6000,  87.4600,\n",
      "           4.1400,  91.2100,  16.9700,  84.9500,  18.2500,  87.3600,  21.5200,\n",
      "          89.0500,  15.4500,  64.7300,  12.2100,  74.0600,  27.6600,  88.8400,\n",
      "          13.4600,  88.0400,   6.0000,  88.6000,  22.1000,  87.9500,   7.1700,\n",
      "          87.3100,   5.5000,  89.7500,  13.2300,  84.8300,   7.1400,  89.0600,\n",
      "          19.7400,  92.1000,  22.9200,  82.8900,   6.9900,  88.8600,   6.9700,\n",
      "          88.8600,   9.5400,  88.1400,   4.6600,   0.4400,   0.4100],\n",
      "        [102.2200,  13.6100,  66.9300,  19.8600,  80.6100,  19.3300,  84.1500,\n",
      "          28.1300,  83.7600,   8.2300,  83.6500,  16.9700,  82.7500,  21.3900,\n",
      "          84.4700,  35.4800,  78.6300,   9.7200,  82.0200,  12.1900,  82.7500,\n",
      "          10.5500,  86.0800,  24.4400,  75.7200,  19.4500,  85.6500,  33.7300,\n",
      "          83.1700,  21.9400,  84.8100,  17.4000,  88.8100,  10.3300,  85.1000,\n",
      "          12.2300,  87.3000,  24.1100,  82.9300,  18.6300,  82.9200,  18.2300,\n",
      "          88.4000,  26.2800, 101.8800,  13.2400,   0.6800,   0.2200]])\n",
      "torch.Size([2, 48])\n"
     ]
    }
   ],
   "source": [
    "play = sample_from_plays(2, df)\n",
    "\n",
    "print(torch.tensor(np.stack(play['state'].values)))\n",
    "\n",
    "print(\"################\")\n",
    "\n",
    "state = torch.tensor(np.stack(play['state'].values), dtype=torch.float32)\n",
    "next_state = torch.tensor(np.stack(play['next_state'].values), dtype=torch.float32)\n",
    "reward = torch.tensor(play['reward'].values)\n",
    "true_action = torch.tensor(np.stack(play['action'].values), dtype=torch.float32)\n",
    "\n",
    "# print(play['action'].values)\n",
    "# print(torch.tensor(play['action']))\n",
    "\n",
    "print(state)\n",
    "print(next_state)\n",
    "print(reward)\n",
    "print(true_action)\n",
    "print(\"####################\")\n",
    "\n",
    "print(state.size())\n",
    "print(true_action.size())\n",
    "cat =torch.cat((state,true_action), 1)\n",
    "print(cat)\n",
    "print(cat.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "id": "335b7f3d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Actor states: tensor([[0.0000, 7.6483],\n",
      "        [0.0000, 6.5292]], grad_fn=<ReluBackward0>)\n",
      "Critic targets: tensor([[3.4059],\n",
      "        [3.6254]], grad_fn=<ReluBackward0>)\n",
      "torch.Size([2])\n",
      "torch.Size([2, 1])\n",
      "tensor([[3.9719, 4.0819],\n",
      "        [4.1891, 4.2991]], dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "torch.Size([2, 46])\n",
      "torch.Size([2, 2])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor(-3.4946, grad_fn=<NegBackward>)"
      ]
     },
     "execution_count": 233,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "actor_states = actor_target(next_state)\n",
    "\n",
    "print(f\"Actor states: {actor_states}\")\n",
    "\n",
    "# concat state (N, X) and action (N, Y)\n",
    "inp = torch.cat((next_state, actor_states), 1)\n",
    "\n",
    "ta = critic_target(inp)\n",
    "\n",
    "print(f\"Critic targets: {ta}\")\n",
    "\n",
    "print(reward.shape)\n",
    "print(ta.shape)\n",
    "\n",
    "y = reward + gamma*ta\n",
    "print(y)\n",
    "\n",
    "print(state.shape)\n",
    "print(actor(state).shape)\n",
    "\n",
    "-critic(torch.cat((state, actor(state)),1)).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "id": "892c71ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.float32\n",
      "torch.float32\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "for k in range(iterations):\n",
    "    \n",
    "    play = sample_from_plays(2, df)\n",
    "    \n",
    "    for time_step in play:\n",
    "\n",
    "        state = torch.tensor(np.stack(play['state'].values), dtype=torch.float32)\n",
    "        next_state = torch.tensor(np.stack(play['next_state'].values), dtype=torch.float32)\n",
    "        reward = torch.tensor(play['reward'].values)\n",
    "        true_action = torch.tensor(np.stack(play['action'].values), dtype=torch.float32)\n",
    "\n",
    "        actor_states = actor_target(next_state)\n",
    "        critic_input_from_actor = torch.cat((next_state, actor_states), 1)\n",
    "\n",
    "        # set y values\n",
    "        y = reward + gamma*critic_target(critic_input_from_actor)\n",
    "        y = y.to(torch.float32)\n",
    "        \n",
    "        #\n",
    "        critic_input_true_actions = torch.cat((next_state, true_action), 1)\n",
    "        true_y = critic(critic_input_true_actions)\n",
    "        \n",
    "        print(true_y.dtype)\n",
    "        print(y.dtype)\n",
    "        \n",
    "        # update critic\n",
    "        critic.zero_grad()\n",
    "        critic_loss = critic_loss_function(y, true_y)\n",
    "        critic_loss.backward()\n",
    "        critic_optimizer.step()\n",
    "        \n",
    "        # update actor\n",
    "        policy_loss = -critic(torch.cat((state, actor(state)),1))\n",
    "        policy_loss = policy_loss.mean()\n",
    "        policy_loss.backward()\n",
    "        \n",
    "        break\n",
    "        \n",
    "    break\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52bf47f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "actor_loss_function = some_loss_function()\n",
    "actor_optimizer = optim.Adam(actor.parameters())\n",
    "\n",
    "critic_loss_function = some_loss_function()\n",
    "critic_optimizer = optim.Adam(critic.parameters())\n",
    "\n",
    "for k in range(iterations):\n",
    "    \n",
    "    # sample batch_size number of plays\n",
    "    play = sample_from_plays()\n",
    "    \n",
    "    for time_step in play:\n",
    "    states\n",
    "    next_states\n",
    "    rewards \n",
    "    true_actions\n",
    "    \n",
    "    # use actor network to predict action\n",
    "    actor_actions = actor(states)\n",
    "    # update compared\n",
    "    actor_loss = actor_loss_function(actor_actions, true_actions)\n",
    "    actor_optimizer.zero_grad()\n",
    "    actor_loss.backward()\n",
    "    actor_optimizer.step()\n",
    "    \n",
    "    # use critic network to predict q-value\n",
    "    predicted_q = critic(states, true_actions)\n",
    "    q_star = rewards + gamma*predicted_q\n",
    "    \n",
    "    critic_loss = critic_loss_function()\n",
    "    critic_optimizer.zero_grad()\n",
    "    critic_loss.backward()\n",
    "    critic_optimizer.step()\n",
    "    \n",
    "    # sample state\n",
    "    \n",
    "    # get Q-value for (state,action)\n",
    "    \n",
    "    # calc future value - apply each action to state\n",
    "    \n",
    "    \n",
    "    #state = full_state[0,0:6] = ball_carrier_entry.loc[:,['x','y', 's', 'a', 'o', 'dir']]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03d9ea68",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0acb3e9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
