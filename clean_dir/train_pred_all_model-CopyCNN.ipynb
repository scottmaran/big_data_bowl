{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "81c17a19",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import json\n",
    "import pickle\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "import torch.utils.data\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2378d714",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>season</th>\n",
       "      <th>gameId</th>\n",
       "      <th>playId</th>\n",
       "      <th>playIndex</th>\n",
       "      <th>timeIndex</th>\n",
       "      <th>time</th>\n",
       "      <th>playerId</th>\n",
       "      <th>football_pos</th>\n",
       "      <th>state</th>\n",
       "      <th>next_state</th>\n",
       "      <th>reward</th>\n",
       "      <th>action</th>\n",
       "      <th>next_action</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2018</td>\n",
       "      <td>2018090600</td>\n",
       "      <td>677</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2018-09-07T01:34:34.500</td>\n",
       "      <td>44979.0</td>\n",
       "      <td>[[11.15, 42.28, 0.17, 2.91, 6.78, 0.0, 0.0, 11...</td>\n",
       "      <td>[[11.53, 42.45, 0.14, 1.32, 3.03, 117.3, 148.0...</td>\n",
       "      <td>[[11.62, 42.32, 0.16, 1.7, 3.13, 114.42, 144.8...</td>\n",
       "      <td>[-0.09]</td>\n",
       "      <td>[[-0.09, 0.13, -0.02, -0.38, -0.1, 2.88, 3.22,...</td>\n",
       "      <td>[[-0.16, 0.16, -0.07, -0.53, -0.24, -17.77, 7....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2018</td>\n",
       "      <td>2018090600</td>\n",
       "      <td>677</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2018-09-07T01:34:34.600</td>\n",
       "      <td>44979.0</td>\n",
       "      <td>[[11.51, 42.1, 0.39, 1.64, 4.44, 0.0, 0.0, 11....</td>\n",
       "      <td>[[11.62, 42.32, 0.16, 1.7, 3.13, 114.42, 144.8...</td>\n",
       "      <td>[[11.78, 42.16, 0.23, 2.23, 3.37, 132.19, 137....</td>\n",
       "      <td>[-0.16]</td>\n",
       "      <td>[[-0.16, 0.16, -0.07, -0.53, -0.24, -17.77, 7....</td>\n",
       "      <td>[[-0.17, 0.18, -0.01, -0.4, -0.51, 6.53, 2.66,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2018</td>\n",
       "      <td>2018090600</td>\n",
       "      <td>677</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2018-09-07T01:34:34.700</td>\n",
       "      <td>44979.0</td>\n",
       "      <td>[[11.47, 42.06, 0.06, 1.2, 3.4, 0.0, 0.0, 11.4...</td>\n",
       "      <td>[[11.78, 42.16, 0.23, 2.23, 3.37, 132.19, 137....</td>\n",
       "      <td>[[11.95, 41.98, 0.24, 2.63, 3.88, 125.66, 134....</td>\n",
       "      <td>[-0.17]</td>\n",
       "      <td>[[-0.17, 0.18, -0.01, -0.4, -0.51, 6.53, 2.66,...</td>\n",
       "      <td>[[-0.21, 0.19, -0.05, -0.48, -0.22, 4.32, 3.47...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2018</td>\n",
       "      <td>2018090600</td>\n",
       "      <td>677</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>2018-09-07T01:34:34.800</td>\n",
       "      <td>44979.0</td>\n",
       "      <td>[[12.39, 41.68, 1.0, 0.93, 2.17, 0.0, 0.0, 12....</td>\n",
       "      <td>[[11.95, 41.98, 0.24, 2.63, 3.88, 125.66, 134....</td>\n",
       "      <td>[[12.16, 41.79, 0.29, 3.11, 4.1, 121.34, 131.2...</td>\n",
       "      <td>[-0.21]</td>\n",
       "      <td>[[-0.21, 0.19, -0.05, -0.48, -0.22, 4.32, 3.47...</td>\n",
       "      <td>[[-0.25, 0.21, -0.03, -0.44, -0.67, 2.49, 3.83...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2018</td>\n",
       "      <td>2018090600</td>\n",
       "      <td>677</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>2018-09-07T01:34:34.900</td>\n",
       "      <td>44979.0</td>\n",
       "      <td>[[13.5, 41.18, 1.22, 1.47, 3.5, 0.0, 0.0, 13.5...</td>\n",
       "      <td>[[12.16, 41.79, 0.29, 3.11, 4.1, 121.34, 131.2...</td>\n",
       "      <td>[[12.41, 41.58, 0.32, 3.55, 4.77, 118.85, 127....</td>\n",
       "      <td>[-0.25]</td>\n",
       "      <td>[[-0.25, 0.21, -0.03, -0.44, -0.67, 2.49, 3.83...</td>\n",
       "      <td>[[-0.32, 0.21, -0.06, -0.47, -0.03, 0.0, 9.25,...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  season      gameId  playId  playIndex  timeIndex                     time  \\\n",
       "0   2018  2018090600     677          0          0  2018-09-07T01:34:34.500   \n",
       "1   2018  2018090600     677          0          1  2018-09-07T01:34:34.600   \n",
       "2   2018  2018090600     677          0          2  2018-09-07T01:34:34.700   \n",
       "3   2018  2018090600     677          0          3  2018-09-07T01:34:34.800   \n",
       "4   2018  2018090600     677          0          4  2018-09-07T01:34:34.900   \n",
       "\n",
       "   playerId                                       football_pos  \\\n",
       "0   44979.0  [[11.15, 42.28, 0.17, 2.91, 6.78, 0.0, 0.0, 11...   \n",
       "1   44979.0  [[11.51, 42.1, 0.39, 1.64, 4.44, 0.0, 0.0, 11....   \n",
       "2   44979.0  [[11.47, 42.06, 0.06, 1.2, 3.4, 0.0, 0.0, 11.4...   \n",
       "3   44979.0  [[12.39, 41.68, 1.0, 0.93, 2.17, 0.0, 0.0, 12....   \n",
       "4   44979.0  [[13.5, 41.18, 1.22, 1.47, 3.5, 0.0, 0.0, 13.5...   \n",
       "\n",
       "                                               state  \\\n",
       "0  [[11.53, 42.45, 0.14, 1.32, 3.03, 117.3, 148.0...   \n",
       "1  [[11.62, 42.32, 0.16, 1.7, 3.13, 114.42, 144.8...   \n",
       "2  [[11.78, 42.16, 0.23, 2.23, 3.37, 132.19, 137....   \n",
       "3  [[11.95, 41.98, 0.24, 2.63, 3.88, 125.66, 134....   \n",
       "4  [[12.16, 41.79, 0.29, 3.11, 4.1, 121.34, 131.2...   \n",
       "\n",
       "                                          next_state   reward  \\\n",
       "0  [[11.62, 42.32, 0.16, 1.7, 3.13, 114.42, 144.8...  [-0.09]   \n",
       "1  [[11.78, 42.16, 0.23, 2.23, 3.37, 132.19, 137....  [-0.16]   \n",
       "2  [[11.95, 41.98, 0.24, 2.63, 3.88, 125.66, 134....  [-0.17]   \n",
       "3  [[12.16, 41.79, 0.29, 3.11, 4.1, 121.34, 131.2...  [-0.21]   \n",
       "4  [[12.41, 41.58, 0.32, 3.55, 4.77, 118.85, 127....  [-0.25]   \n",
       "\n",
       "                                              action  \\\n",
       "0  [[-0.09, 0.13, -0.02, -0.38, -0.1, 2.88, 3.22,...   \n",
       "1  [[-0.16, 0.16, -0.07, -0.53, -0.24, -17.77, 7....   \n",
       "2  [[-0.17, 0.18, -0.01, -0.4, -0.51, 6.53, 2.66,...   \n",
       "3  [[-0.21, 0.19, -0.05, -0.48, -0.22, 4.32, 3.47...   \n",
       "4  [[-0.25, 0.21, -0.03, -0.44, -0.67, 2.49, 3.83...   \n",
       "\n",
       "                                         next_action  \n",
       "0  [[-0.16, 0.16, -0.07, -0.53, -0.24, -17.77, 7....  \n",
       "1  [[-0.17, 0.18, -0.01, -0.4, -0.51, 6.53, 2.66,...  \n",
       "2  [[-0.21, 0.19, -0.05, -0.48, -0.22, 4.32, 3.47...  \n",
       "3  [[-0.25, 0.21, -0.03, -0.44, -0.67, 2.49, 3.83...  \n",
       "4  [[-0.32, 0.21, -0.06, -0.47, -0.03, 0.0, 9.25,...  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "Read in saved dataset to use to feed into the model.\n",
    "Further pre-processing still needs to be done on the state vectors\n",
    "'''\n",
    "\n",
    "data_df = pd.read_pickle('/home/amans/Development/scott/nfl-big-data-bowl-2022/clean_dir/ball_carrier_data.pkl')\n",
    "\n",
    "\n",
    "data_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3b397880",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "18"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "State vector \n",
    "['x','y', 'dis', 's', 'a', 'o', 'dir', 'adj_x', 'adj_y', 'adj_o', 'adj_dir', 'sin_adj_o', 'cos_adj_o', \\\n",
    "'sin_adj_dir', 'cos_adj_dir', 'dist_from_ball_carrier', 'min_teammate_dist', 'min_opponent_dist']\n",
    "'''\n",
    "\n",
    "len(data_df.loc[0,'state'][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9526514",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "723edf01",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d8a40f9c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "size =  torch.Size([192049])\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "Create torch dataset\n",
    "'''\n",
    "\n",
    "features = torch.zeros(len(data_df)).to(device)\n",
    "labels = torch.zeros(len(data_df)).to(device)\n",
    "\n",
    "print(\"size = \", features.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "91376685",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['season', 'gameId', 'playId', 'playIndex', 'timeIndex', 'time',\n",
      "       'playerId', 'football_pos', 'state', 'next_state', 'reward', 'action',\n",
      "       'next_action'],\n",
      "      dtype='object')\n",
      "Length of training data: 134434\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "Function that splits the data into a training, validation, and test set\n",
    "'''\n",
    "def split_data(dataset, train_split, seed):\n",
    "    np.random.seed(seed)\n",
    "    indices = list(range(len(dataset)))\n",
    "    np.random.shuffle(indices)\n",
    "\n",
    "    train_num = int(len(dataset)*train_split)\n",
    "    val_num = (len(dataset) - int(len(dataset)*train_split))//2\n",
    "\n",
    "    train_indices = indices[0:train_num]\n",
    "    val_indices = indices[train_num:train_num+val_num]\n",
    "    test_indices = indices[train_num+val_num:]\n",
    "\n",
    "    #check to make sure slices correct\n",
    "    assert len(dataset) == len(train_indices) + len(val_indices) + len(test_indices)\n",
    "\n",
    "    #dataset = help.normalize(train_indices, dataset)\n",
    "\n",
    "    train_data = dataset.iloc[train_indices,:]\n",
    "    val_data = dataset.iloc[val_indices,:]\n",
    "    test_data = dataset.iloc[test_indices,:]\n",
    "\n",
    "    return train_data, val_data, test_data\n",
    "\n",
    "train_data, val_data, test_data = split_data(data_df, 0.7, 2430)\n",
    "\n",
    "print(test_data.columns)\n",
    "\n",
    "print(f\"Length of training data: {len(train_data)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "200b93b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "State size: 18\n",
      "Action size: 8\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'\\nFirst CNN model\\ncnn_model = nn.Sequential(\\n    nn.Conv2d(1, 12, (12,1), stride=1, padding=0),\\n    nn.LeakyReLU(),\\n    nn.Conv2d(12, 24, (6, 1)),\\n    nn.LeakyReLU(),\\n    nn.Conv2d(24, 48, (1,1)),\\n    nn.Flatten(),\\n    nn.Linear(48*6*6,action_size)\\n)\\n\\ncnn_model.to(device=device)\\n'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "Predict ['s', 'a', 'adj_x', 'adj_y', 'adj_o', 'adj_dir', 'sin_adj_o', 'cos_adj_o', 'sin_adj_dir', 'cos_adj_dir']\n",
    "from \n",
    "['x','y', 'dis', 's', 'a', 'o', 'dir', 'adj_x', 'adj_y', 'adj_o', 'adj_dir', 'sin_adj_o', 'cos_adj_o', \\\n",
    "'sin_adj_dir', 'cos_adj_dir', 'dist_from_ball_carrier', 'min_teammate_dist', 'min_opponent_dist']\n",
    "'''\n",
    "\n",
    "\n",
    "\n",
    "'''\n",
    "Define hyperparamters\n",
    "'''\n",
    "BATCH_SIZE = 32\n",
    "state_size = len(data_df.loc[0,'state'][0])\n",
    "action_size = 8\n",
    "gamma = 0.99\n",
    "#max_action = torch.tensor(max_action, dtype=torch.float32).to(device=device)\n",
    "\n",
    "print(f\"State size: {state_size}\")\n",
    "print(f\"Action size: {action_size}\")\n",
    "    \n",
    "'''\n",
    "First CNN model\n",
    "cnn_model = nn.Sequential(\n",
    "    nn.Conv2d(1, 12, (12,1), stride=1, padding=0),\n",
    "    nn.LeakyReLU(),\n",
    "    nn.Conv2d(12, 24, (6, 1)),\n",
    "    nn.LeakyReLU(),\n",
    "    nn.Conv2d(24, 48, (1,1)),\n",
    "    nn.Flatten(),\n",
    "    nn.Linear(48*6*6,action_size)\n",
    ")\n",
    "\n",
    "cnn_model.to(device=device)\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c950c557",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e408d950",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nTry model predicting entire sequence\\n'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "Try model predicting entire sequence\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "97ca561e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sequential(\n",
       "  (0): Linear(in_features=253, out_features=230, bias=True)\n",
       "  (1): LeakyReLU(negative_slope=0.01)\n",
       "  (2): Linear(in_features=230, out_features=184, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "same results, not great val loss and then overfit\n",
    "'''\n",
    "# cnn_model = nn.Sequential(\n",
    "#     nn.Conv2d(1, 32, (3,3), stride=1,padding=0),\n",
    "#     nn.LeakyReLU(),\n",
    "#     #nn.MaxPool2d((2,2), stride=2),\n",
    "#     nn.Conv2d(32, 64, (3,3), stride=1,padding=0),\n",
    "#     nn.LeakyReLU(),\n",
    "#     #nn.MaxPool2d((2,2), stride=2),\n",
    "#     nn.Conv2d(64,128, (2,2), stride=1,padding=0),\n",
    "#     nn.LeakyReLU(),\n",
    "#     #nn.MaxPool2d((2,2), stride=2),\n",
    "#     nn.Conv2d(128,256, (1,1), stride=1,padding=0),\n",
    "#     nn.LeakyReLU(),\n",
    "#     #nn.MaxPool2d((2,2), stride=2),\n",
    "#     #nn.Conv2d(256,512, (3,3), stride=1,padding=0),\n",
    "#     #nn.LeakyReLU(),\n",
    "#     #nn.MaxPool2d((2,2), stride=2),\n",
    "#     nn.Flatten(),\n",
    "#     nn.Linear(13824, 6000),\n",
    "#     nn.LeakyReLU(),\n",
    "#     nn.Linear(6000, 2000),\n",
    "#     nn.LeakyReLU(),\n",
    "#     nn.Linear(2000, 500),\n",
    "#     nn.LeakyReLU(),\n",
    "#     nn.Linear(500, action_size*23)\n",
    "# )\n",
    "\n",
    "'''\n",
    "val loss @ .3 after 4 epochs, .287 after 7 epochs, .286 after 8 epochs\n",
    "'''\n",
    "# cnn_model = nn.Sequential(\n",
    "#     nn.Conv2d(1, 6, (2,2), stride=1, padding=0),\n",
    "#     nn.Flatten(),\n",
    "#     nn.Linear(924,400), \n",
    "#     nn.LeakyReLU(),\n",
    "#     nn.Linear(400,action_size*23)\n",
    "# )\n",
    "\n",
    "'''\n",
    "Similar val losses. .359 val loss after 3 epochs, .313 after 4\n",
    "'''\n",
    "# cnn_model = nn.Sequential(\n",
    "#     nn.Conv2d(1, 3, (2,2), stride=1, padding=0),\n",
    "#     nn.Flatten(),\n",
    "#     nn.Linear(462,230), \n",
    "#     nn.LeakyReLU(),\n",
    "#     nn.Linear(230,action_size*23)\n",
    "# )\n",
    "\n",
    "'''\n",
    "Similar val losses, .283 val loss after 2 epochs, .281 after 4\n",
    "'''\n",
    "# cnn_model = nn.Sequential(\n",
    "#     nn.BatchNorm2d(1),\n",
    "#     nn.Conv2d(1, 32, (8,8), stride=1, padding=0),\n",
    "#     nn.Flatten(),\n",
    "#     nn.Linear(128*4,230), \n",
    "#     nn.LeakyReLU(),\n",
    "#     nn.Linear(230,action_size*23)\n",
    "# )\n",
    "\n",
    "\n",
    "'''\n",
    "Predicting next state\n",
    "'''\n",
    "'''\n",
    "class cnnModel(nn.Module):\n",
    "    def __init__(self, action_size):\n",
    "        super(cnnModel, self).__init__()\n",
    "        \n",
    "        self.action_size = action_size\n",
    "        \n",
    "        self.batch_norm = nn.BatchNorm1d(8)\n",
    "        self.conv1 = nn.Conv2d(1, 32, (8,8), stride=1, padding=0)\n",
    "        self.flatten = nn.Flatten()\n",
    "        self.linear1 = nn.Linear(128*4,230)\n",
    "        self.leaky = nn.LeakyReLU()\n",
    "        self.linear2 = nn.Linear(230,action_size*23)\n",
    "        \n",
    "        self.drop = nn.Dropout(.5)\n",
    "        \n",
    "    # input (batch_size, 1, 23, action_size)\n",
    "    def forward(self, input_tensor):\n",
    "        \n",
    "        #tens_reshape = input_tensor.view(-1, 23, 8)\n",
    "        initial_shape = input_tensor.shape\n",
    "        \n",
    "        batched_input = self.batch_norm(torch.transpose(input_tensor.view(-1, 23, 8), 1,2))\n",
    "        \n",
    "        inp = torch.transpose(batched_input, 1, 2).view(initial_shape)\n",
    "        \n",
    "        output = self.conv1(inp)\n",
    "        output = self.flatten(output)\n",
    "        output = self.drop(output)\n",
    "        output = self.linear1(output)\n",
    "        output = self.leaky(output)\n",
    "        output = self.linear2(output)\n",
    "        \n",
    "        return output\n",
    "cnn_model = cnnModel(action_size)\n",
    "'''\n",
    "\n",
    "# after 50 epochs, 0.3251 val loss with small dataset model\n",
    "\n",
    "cnn_model = nn.Sequential(\n",
    "    nn.Linear(23*11,230), \n",
    "    nn.LeakyReLU(),\n",
    "    nn.Linear(230,23*8)\n",
    ")\n",
    "\n",
    "cnn_model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "90e4f937",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.optim.lr_scheduler import LambdaLR\n",
    "from torch.optim.lr_scheduler import ExponentialLR\n",
    "\n",
    "#cnn_model.load_state_dict(torch.load(\"full_dataset_model.pt\"))\n",
    "\n",
    "# define loss function\n",
    "mse_loss_fn = nn.MSELoss()\n",
    "#mse_loss_fn = nn.L1Loss()\n",
    "# define optimizers\n",
    "cnn_optimizer = optim.Adam(cnn_model.parameters(), lr=0.005)\n",
    "\n",
    "#scheduler = ExponentialLR(cnn_optimizer, gamma=0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "fc2de624",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[42412.]\n",
      " [48988.]\n",
      " [46309.]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(3, 3)"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_play = train_data.iloc[[2,3,4],:]\n",
    "\n",
    "ids = np.array(test_play.loc[:,'playerId']).reshape(3,1)\n",
    "\n",
    "print(ids)\n",
    "\n",
    "np.append(np.zeros((3,2)), ids, axis=1).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "5cce47a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Given indices, train model on batch\n",
    "['x','y', 'dis', 's', 'a', 'o', 'dir', 'adj_x', 'adj_y', 'adj_o', 'adj_dir', 'sin_adj_o', 'cos_adj_o', \\\n",
    "'sin_adj_dir', 'cos_adj_dir', 'dist_from_ball_carrier', 'min_teammate_dist', 'min_opponent_dist']\n",
    "\n",
    "Try adding player id as feature\n",
    "'''\n",
    "def train_loop_large(df, indices, model, loss_fn, optimizer, device):\n",
    "    size = len(indices)\n",
    "    play = df.iloc[indices, :]\n",
    "    \n",
    "    numpy_state = np.stack(play['state'].values)\n",
    "    numpy_next_state = np.stack(play['next_state'].values)\n",
    "    batch_size = numpy_state.shape[0]\n",
    "    playerId = np.array(play.loc[:,'playerId']).reshape(batch_size, 1)\n",
    "    \n",
    "    #print(numpy_state.shape)\n",
    "    #print(numpy_next_state.shape)\n",
    "    #print(numpy_state[:,:,[2,3,4,7,8,11,12,13,14,16,17]])\n",
    "\n",
    "    numpy_reshaped_state = numpy_state[:,:,[2,3,4,7,8,11,12,13,14,16,17]]\n",
    "    numpy_reshaped_state = numpy_reshaped_state.reshape(batch_size, -1)\n",
    "    #numpy_with_playerid = np.append(numpy_reshaped_state, playerId, axis=1)\n",
    "    true_state = torch.tensor(numpy_reshaped_state, dtype=torch.float32).to(device=device)\n",
    "    \n",
    "    numpy_reshaped_next_state = numpy_next_state[:,:,[3,4,7,8,11,12,13,14]]\n",
    "    numpy_reshaped_next_state = numpy_reshaped_next_state.reshape(batch_size, -1)\n",
    "    #numpy_next_with_playerid = np.append(numpy_reshaped_next_state, playerId, axis=1)\n",
    "    true_next_state = torch.tensor(numpy_reshaped_next_state, dtype=torch.float32).to(device=device)\n",
    "    \n",
    "    # shape true state into matrix to pass into CNN\n",
    "    #true_state_mod = torch.tensor(numpy_state_input, dtype=torch.float32).to(device=device)\n",
    "\n",
    "    model.train()  # put model to training mode\n",
    "\n",
    "    #compute prediction and loss\n",
    "    predicted_next_state = model(true_state)\n",
    "    \n",
    "    loss = loss_fn(predicted_next_state, true_next_state)\n",
    "\n",
    "    #Backpropagation\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    \n",
    "    return loss/size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "80c3d5b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_loop_large(test_df, model, loss_fn, device):\n",
    "    size = len(test_df)\n",
    "    test_loss = 0\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for row_index in range(0,len(test_df)):\n",
    "\n",
    "            play = test_df.iloc[row_index, :]\n",
    "\n",
    "            numpy_state = np.stack(play['state'])\n",
    "            numpy_next_state = np.stack(play['next_state'])\n",
    "            batch_size = 1\n",
    "            playerId = np.array(play.loc['playerId']).reshape(batch_size, 1)\n",
    "            \n",
    "            #print(numpy_state.shape)\n",
    "            \n",
    "            numpy_reshaped_state = numpy_state[:,[2,3,4,7,8,11,12,13,14,16,17]]\n",
    "            numpy_reshaped_state = numpy_reshaped_state.reshape(batch_size, -1)\n",
    "            #numpy_with_playerid = np.append(numpy_reshaped_state, playerId, axis=1)\n",
    "            true_state = torch.tensor(numpy_reshaped_state, dtype=torch.float32).to(device=device)\n",
    "\n",
    "            numpy_reshaped_next_state = numpy_next_state[:,[3,4,7,8,11,12,13,14]]\n",
    "            numpy_reshaped_next_state = numpy_reshaped_next_state.reshape(batch_size, -1)\n",
    "            #numpy_next_with_playerid = np.append(numpy_reshaped_next_state, playerId, axis=1)\n",
    "            true_next_state = torch.tensor(numpy_reshaped_next_state, dtype=torch.float32).to(device=device)\n",
    "            \n",
    "            model.eval()  # put model to eval mode\n",
    "\n",
    "            #compute prediction and loss\n",
    "            predicted_next_state = model(true_state)\n",
    "  \n",
    "            loss = loss_fn(predicted_next_state, true_next_state)\n",
    "            \n",
    "            test_loss += loss\n",
    "        \n",
    "        test_loss = test_loss/size\n",
    "\n",
    "    \n",
    "    return test_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "134032b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num batches: 4202\n",
      "At epoch 0, iter 0: train loss = 7.637215614318848\n",
      "At epoch 0, iter 0: val loss = 180.95370483398438\n",
      "At epoch 0, iter 1400: train loss = 0.033417899161577225\n",
      "At epoch 0, iter 1400: val loss = 0.9668441414833069\n",
      "At epoch 0, iter 2800: train loss = 0.024148376658558846\n",
      "At epoch 0, iter 2800: val loss = 0.64189612865448\n",
      "At epoch 0, iter 4200: train loss = 0.017724255099892616\n",
      "At epoch 0, iter 4200: val loss = 0.6274528503417969\n",
      "post scheduler step lr =  0.0025\n",
      "At epoch 1, iter 0: train loss = 0.027474917471408844\n",
      "At epoch 1, iter 0: val loss = 0.6237711310386658\n",
      "At epoch 1, iter 1400: train loss = 0.014218095690011978\n",
      "At epoch 1, iter 1400: val loss = 0.4647950530052185\n",
      "At epoch 1, iter 2800: train loss = 0.01351973321288824\n",
      "At epoch 1, iter 2800: val loss = 0.4567682445049286\n",
      "At epoch 1, iter 4200: train loss = 0.012781878001987934\n",
      "At epoch 1, iter 4200: val loss = 0.40662747621536255\n",
      "post scheduler step lr =  0.00125\n",
      "At epoch 2, iter 0: train loss = 0.017307305708527565\n",
      "At epoch 2, iter 0: val loss = 0.4226924479007721\n",
      "At epoch 2, iter 1400: train loss = 0.01049747597426176\n",
      "At epoch 2, iter 1400: val loss = 0.35804903507232666\n",
      "At epoch 2, iter 2800: train loss = 0.010344772599637508\n",
      "At epoch 2, iter 2800: val loss = 0.3326835036277771\n",
      "At epoch 2, iter 4200: train loss = 0.010280091315507889\n",
      "At epoch 2, iter 4200: val loss = 0.32410991191864014\n",
      "post scheduler step lr =  0.000625\n",
      "At epoch 3, iter 0: train loss = 0.012156377546489239\n",
      "At epoch 3, iter 0: val loss = 0.37111836671829224\n",
      "At epoch 3, iter 1400: train loss = 0.009441673755645752\n",
      "At epoch 3, iter 1400: val loss = 0.30882224440574646\n",
      "At epoch 3, iter 2800: train loss = 0.009547925554215908\n",
      "At epoch 3, iter 2800: val loss = 0.30972209572792053\n",
      "At epoch 3, iter 4200: train loss = 0.009449733421206474\n",
      "At epoch 3, iter 4200: val loss = 0.30604273080825806\n",
      "post scheduler step lr =  0.0003125\n",
      "At epoch 4, iter 0: train loss = 0.00960017740726471\n",
      "At epoch 4, iter 0: val loss = 0.32515063881874084\n",
      "At epoch 4, iter 1400: train loss = 0.008851971477270126\n",
      "At epoch 4, iter 1400: val loss = 0.2921240031719208\n",
      "At epoch 4, iter 2800: train loss = 0.00928355660289526\n",
      "At epoch 4, iter 2800: val loss = 0.29291343688964844\n",
      "At epoch 4, iter 4200: train loss = 0.009005806408822536\n",
      "At epoch 4, iter 4200: val loss = 0.29412323236465454\n",
      "post scheduler step lr =  0.00015625\n",
      "At epoch 5, iter 0: train loss = 0.009305211715400219\n",
      "At epoch 5, iter 0: val loss = 0.3097686767578125\n",
      "At epoch 5, iter 1400: train loss = 0.008613132871687412\n",
      "At epoch 5, iter 1400: val loss = 0.28708788752555847\n",
      "At epoch 5, iter 2800: train loss = 0.009080147370696068\n",
      "At epoch 5, iter 2800: val loss = 0.28800180554389954\n",
      "At epoch 5, iter 4200: train loss = 0.008687160909175873\n",
      "At epoch 5, iter 4200: val loss = 0.28688591718673706\n",
      "post scheduler step lr =  7.8125e-05\n",
      "At epoch 6, iter 0: train loss = 0.008954931981861591\n",
      "At epoch 6, iter 0: val loss = 0.29213252663612366\n",
      "At epoch 6, iter 1400: train loss = 0.008799128234386444\n",
      "At epoch 6, iter 1400: val loss = 0.283955454826355\n",
      "At epoch 6, iter 2800: train loss = 0.008651312440633774\n",
      "At epoch 6, iter 2800: val loss = 0.28402286767959595\n",
      "At epoch 6, iter 4200: train loss = 0.008690900169312954\n",
      "At epoch 6, iter 4200: val loss = 0.2837415337562561\n",
      "post scheduler step lr =  3.90625e-05\n",
      "At epoch 7, iter 0: train loss = 0.008687461726367474\n",
      "At epoch 7, iter 0: val loss = 0.28564053773880005\n",
      "At epoch 7, iter 1400: train loss = 0.009065927937626839\n",
      "At epoch 7, iter 1400: val loss = 0.28241798281669617\n",
      "At epoch 7, iter 2800: train loss = 0.008569080382585526\n",
      "At epoch 7, iter 2800: val loss = 0.28172412514686584\n",
      "At epoch 7, iter 4200: train loss = 0.008769942447543144\n",
      "At epoch 7, iter 4200: val loss = 0.2814908027648926\n",
      "post scheduler step lr =  1.953125e-05\n",
      "At epoch 8, iter 0: train loss = 0.008839157409965992\n",
      "At epoch 8, iter 0: val loss = 0.2822818160057068\n",
      "At epoch 8, iter 1400: train loss = 0.00863422080874443\n",
      "At epoch 8, iter 1400: val loss = 0.28058895468711853\n",
      "At epoch 8, iter 2800: train loss = 0.008665441535413265\n",
      "At epoch 8, iter 2800: val loss = 0.28070658445358276\n",
      "At epoch 8, iter 4200: train loss = 0.008883805945515633\n",
      "At epoch 8, iter 4200: val loss = 0.2807285189628601\n",
      "post scheduler step lr =  9.765625e-06\n",
      "At epoch 9, iter 0: train loss = 0.008615618571639061\n",
      "At epoch 9, iter 0: val loss = 0.2809654474258423\n",
      "At epoch 9, iter 1400: train loss = 0.00869265478104353\n",
      "At epoch 9, iter 1400: val loss = 0.2802429497241974\n",
      "At epoch 9, iter 2800: train loss = 0.008447601459920406\n",
      "At epoch 9, iter 2800: val loss = 0.2801055312156677\n",
      "At epoch 9, iter 4200: train loss = 0.008674063719809055\n",
      "At epoch 9, iter 4200: val loss = 0.28026098012924194\n",
      "post scheduler step lr =  4.8828125e-06\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "\n",
    "epochs = 10\n",
    "training_loss_list = []\n",
    "val_loss_list = []\n",
    "\n",
    "num_batches = int(len(train_data)/BATCH_SIZE)+1\n",
    "\n",
    "print(f\"Num batches: {num_batches}\")\n",
    "\n",
    "indexes = list(range(0,len(train_data)))\n",
    "\n",
    "np.random.seed(2430)\n",
    "\n",
    "for k in range(epochs):\n",
    "    \n",
    "    random.shuffle(indexes)\n",
    "    \n",
    "    for i in range(num_batches):\n",
    "\n",
    "        start_index = i*BATCH_SIZE\n",
    "        end_index = min(len(train_data), (i+1)*BATCH_SIZE)\n",
    "        \n",
    "        #indices = list(range(start_index, end_index))\n",
    "        indices = indexes[start_index:end_index]\n",
    "\n",
    "        train_loss = train_loop_large(train_data, indices, cnn_model, mse_loss_fn, cnn_optimizer, device)\n",
    "        \n",
    "        training_loss_list.append(train_loss)\n",
    "\n",
    "        if (i % int(num_batches/3) == 0):\n",
    "        #if (i % int(num_batches) == 0):# and (i != 0):\n",
    "            #for g in cnn_optimizer.param_groups:\n",
    "                #g['lr'] = 0.001\n",
    "                #print(g['lr'])\n",
    "\n",
    "            val_loss = test_loop_large(val_data, cnn_model, F.mse_loss, device)\n",
    "            val_loss_list.append(val_loss)\n",
    "            print(f\"At epoch {k}, iter {i}: train loss = {train_loss}\")\n",
    "            print(f\"At epoch {k}, iter {i}: val loss = {val_loss}\")\n",
    "    \n",
    "    for g in cnn_optimizer.param_groups:\n",
    "        g['lr'] /= 2\n",
    "        print('post scheduler step lr = ', g['lr'])\n",
    "            \n",
    "    #if k > 20 and k % 5 == 0:\n",
    "    #    for g in cnn_optimizer.param_groups:\n",
    "    #        #g['lr'] = 0.001\n",
    "    #        g['lr'] /= 2\n",
    "    #        print('post scheduler step lr = ', g['lr'])\n",
    "\n",
    "    #scheduler.step()\n",
    "            \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "3f6a8913",
   "metadata": {},
   "outputs": [],
   "source": [
    "#torch.save(cnn_model.state_dict(), 'full_dataset_model.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abf33d74",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_baseline(test_df, loss_fn):\n",
    "    size = len(test_df)\n",
    "    test_loss = 0\n",
    "\n",
    "    for row_index in range(0,len(test_df)):\n",
    "        \n",
    "        play = test_df.iloc[row_index, :]\n",
    "\n",
    "        true_state = torch.tensor(play['state'][:,[3,4,7,8,11,12,13,14]].reshape(-1), dtype=torch.float32)\n",
    "        true_next_state = torch.tensor(play['next_state'][:,[3,4,7,8,11,12,13,14]].reshape(-1), dtype=torch.float32)\n",
    "\n",
    "        loss = loss_fn(true_next_state, true_state)\n",
    "\n",
    "        test_loss += loss\n",
    "\n",
    "    test_loss = test_loss/size\n",
    "    \n",
    "    return test_loss\n",
    "\n",
    "val_loss = test_baseline(val_data, F.mse_loss)\n",
    "print('val loss ', val_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "210a8c10",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "728908a4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd6d80c0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
