{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "81c17a19",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import json\n",
    "import pickle\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "import torch.utils.data\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2378d714",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>season</th>\n",
       "      <th>gameId</th>\n",
       "      <th>playId</th>\n",
       "      <th>playIndex</th>\n",
       "      <th>timeIndex</th>\n",
       "      <th>time</th>\n",
       "      <th>playerId</th>\n",
       "      <th>football_pos</th>\n",
       "      <th>state</th>\n",
       "      <th>next_state</th>\n",
       "      <th>reward</th>\n",
       "      <th>action</th>\n",
       "      <th>next_action</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2018</td>\n",
       "      <td>2018090600</td>\n",
       "      <td>677</td>\n",
       "      <td>0</td>\n",
       "      <td>52</td>\n",
       "      <td>2018-09-07T01:34:34.500</td>\n",
       "      <td>42515.0</td>\n",
       "      <td>[[11.15, 42.28, 0.17, 2.91, 6.78, 0.0, 0.0, 11...</td>\n",
       "      <td>[[32.17, 38.71, 0.34, 3.44, 3.64, 78.81, 341.2...</td>\n",
       "      <td>[[32.07, 39.05, 0.35, 3.57, 3.48, 76.56, 346.4...</td>\n",
       "      <td>[-0.09]</td>\n",
       "      <td>[[0.1, -0.34, -0.01, -0.13, 0.16, 2.25, -5.16,...</td>\n",
       "      <td>[[-0.21, -0.11, -0.01, -0.16, -0.2, 2.99, -10....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2018</td>\n",
       "      <td>2018090600</td>\n",
       "      <td>677</td>\n",
       "      <td>0</td>\n",
       "      <td>52</td>\n",
       "      <td>2018-09-07T01:34:34.500</td>\n",
       "      <td>43442.0</td>\n",
       "      <td>[[11.15, 42.28, 0.17, 2.91, 6.78, 0.0, 0.0, 11...</td>\n",
       "      <td>[[21.67, 43.81, 0.23, 2.35, 3.25, 145.89, 56.5...</td>\n",
       "      <td>[[21.88, 43.92, 0.24, 2.51, 3.45, 142.9, 67.26...</td>\n",
       "      <td>[-0.09]</td>\n",
       "      <td>[[-0.21, -0.11, -0.01, -0.16, -0.2, 2.99, -10....</td>\n",
       "      <td>[[0.39, -0.34, 0.02, 0.29, -0.37, 0.0, -4.31, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2018</td>\n",
       "      <td>2018090600</td>\n",
       "      <td>677</td>\n",
       "      <td>0</td>\n",
       "      <td>52</td>\n",
       "      <td>2018-09-07T01:34:34.500</td>\n",
       "      <td>43497.0</td>\n",
       "      <td>[[11.15, 42.28, 0.17, 2.91, 6.78, 0.0, 0.0, 11...</td>\n",
       "      <td>[[34.23, 31.98, 0.54, 5.36, 3.09, 83.47, 308.5...</td>\n",
       "      <td>[[33.84, 32.32, 0.52, 5.07, 3.46, 83.47, 312.8...</td>\n",
       "      <td>[-0.09]</td>\n",
       "      <td>[[0.39, -0.34, 0.02, 0.29, -0.37, 0.0, -4.31, ...</td>\n",
       "      <td>[[0.21, -0.35, 0.0, -0.07, 0.21, -2.28, -3.53,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2018</td>\n",
       "      <td>2018090600</td>\n",
       "      <td>677</td>\n",
       "      <td>0</td>\n",
       "      <td>52</td>\n",
       "      <td>2018-09-07T01:34:34.500</td>\n",
       "      <td>46118.0</td>\n",
       "      <td>[[11.15, 42.28, 0.17, 2.91, 6.78, 0.0, 0.0, 11...</td>\n",
       "      <td>[[33.75, 35.52, 0.4, 3.96, 2.34, 52.95, 327.5,...</td>\n",
       "      <td>[[33.54, 35.87, 0.4, 4.03, 2.13, 55.23, 331.03...</td>\n",
       "      <td>[-0.09]</td>\n",
       "      <td>[[0.21, -0.35, 0.0, -0.07, 0.21, -2.28, -3.53,...</td>\n",
       "      <td>[[-0.36, -0.36, 0.0, 0.02, -0.51, -6.83, -8.95...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2018</td>\n",
       "      <td>2018090600</td>\n",
       "      <td>677</td>\n",
       "      <td>0</td>\n",
       "      <td>52</td>\n",
       "      <td>2018-09-07T01:34:34.500</td>\n",
       "      <td>45599.0</td>\n",
       "      <td>[[11.15, 42.28, 0.17, 2.91, 6.78, 0.0, 0.0, 11...</td>\n",
       "      <td>[[20.92, 38.29, 0.52, 5.16, 5.24, 60.63, 39.12...</td>\n",
       "      <td>[[21.28, 38.65, 0.52, 5.14, 5.75, 67.46, 48.07...</td>\n",
       "      <td>[-0.09]</td>\n",
       "      <td>[[-0.36, -0.36, 0.0, 0.02, -0.51, -6.83, -8.95...</td>\n",
       "      <td>[[0.42, -0.24, 0.01, 0.09, -0.09, -3.73, 2.71,...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  season      gameId  playId  playIndex  timeIndex                     time  \\\n",
       "0   2018  2018090600     677          0         52  2018-09-07T01:34:34.500   \n",
       "1   2018  2018090600     677          0         52  2018-09-07T01:34:34.500   \n",
       "2   2018  2018090600     677          0         52  2018-09-07T01:34:34.500   \n",
       "3   2018  2018090600     677          0         52  2018-09-07T01:34:34.500   \n",
       "4   2018  2018090600     677          0         52  2018-09-07T01:34:34.500   \n",
       "\n",
       "   playerId                                       football_pos  \\\n",
       "0   42515.0  [[11.15, 42.28, 0.17, 2.91, 6.78, 0.0, 0.0, 11...   \n",
       "1   43442.0  [[11.15, 42.28, 0.17, 2.91, 6.78, 0.0, 0.0, 11...   \n",
       "2   43497.0  [[11.15, 42.28, 0.17, 2.91, 6.78, 0.0, 0.0, 11...   \n",
       "3   46118.0  [[11.15, 42.28, 0.17, 2.91, 6.78, 0.0, 0.0, 11...   \n",
       "4   45599.0  [[11.15, 42.28, 0.17, 2.91, 6.78, 0.0, 0.0, 11...   \n",
       "\n",
       "                                               state  \\\n",
       "0  [[32.17, 38.71, 0.34, 3.44, 3.64, 78.81, 341.2...   \n",
       "1  [[21.67, 43.81, 0.23, 2.35, 3.25, 145.89, 56.5...   \n",
       "2  [[34.23, 31.98, 0.54, 5.36, 3.09, 83.47, 308.5...   \n",
       "3  [[33.75, 35.52, 0.4, 3.96, 2.34, 52.95, 327.5,...   \n",
       "4  [[20.92, 38.29, 0.52, 5.16, 5.24, 60.63, 39.12...   \n",
       "\n",
       "                                          next_state   reward  \\\n",
       "0  [[32.07, 39.05, 0.35, 3.57, 3.48, 76.56, 346.4...  [-0.09]   \n",
       "1  [[21.88, 43.92, 0.24, 2.51, 3.45, 142.9, 67.26...  [-0.09]   \n",
       "2  [[33.84, 32.32, 0.52, 5.07, 3.46, 83.47, 312.8...  [-0.09]   \n",
       "3  [[33.54, 35.87, 0.4, 4.03, 2.13, 55.23, 331.03...  [-0.09]   \n",
       "4  [[21.28, 38.65, 0.52, 5.14, 5.75, 67.46, 48.07...  [-0.09]   \n",
       "\n",
       "                                              action  \\\n",
       "0  [[0.1, -0.34, -0.01, -0.13, 0.16, 2.25, -5.16,...   \n",
       "1  [[-0.21, -0.11, -0.01, -0.16, -0.2, 2.99, -10....   \n",
       "2  [[0.39, -0.34, 0.02, 0.29, -0.37, 0.0, -4.31, ...   \n",
       "3  [[0.21, -0.35, 0.0, -0.07, 0.21, -2.28, -3.53,...   \n",
       "4  [[-0.36, -0.36, 0.0, 0.02, -0.51, -6.83, -8.95...   \n",
       "\n",
       "                                         next_action  \n",
       "0  [[-0.21, -0.11, -0.01, -0.16, -0.2, 2.99, -10....  \n",
       "1  [[0.39, -0.34, 0.02, 0.29, -0.37, 0.0, -4.31, ...  \n",
       "2  [[0.21, -0.35, 0.0, -0.07, 0.21, -2.28, -3.53,...  \n",
       "3  [[-0.36, -0.36, 0.0, 0.02, -0.51, -6.83, -8.95...  \n",
       "4  [[0.42, -0.24, 0.01, 0.09, -0.09, -3.73, 2.71,...  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "Read in saved dataset to use to feed into the model.\n",
    "Further pre-processing still needs to be done on the state vectors\n",
    "'''\n",
    "\n",
    "#data_df = pd.read_pickle('/home/amans/Development/scott/nfl-big-data-bowl-2022/clean_dir/from_csv.pkl')\n",
    "data_df = pd.read_pickle('/home/amans/Development/scott/nfl-big-data-bowl-2022/clean_dir/teammate_dataset.pkl')\n",
    "\n",
    "\n",
    "data_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3b397880",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 3.21700000e+01,  3.87100000e+01,  3.40000000e-01,  3.44000000e+00,\n",
       "        3.64000000e+00,  7.88100000e+01,  3.41250000e+02,  3.21700000e+01,\n",
       "        1.20600000e+01,  3.48810000e+02,  2.51250000e+02, -9.30805168e-02,\n",
       "       -9.95658585e-01, -7.73349927e-02,  9.97005165e-01,  2.09760000e+01,\n",
       "        3.56000000e+00,  9.79300000e+00])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "State vector \n",
    "['x','y', 'dis', 's', 'a', 'o', 'dir', 'adj_x', 'adj_y', 'adj_o', 'adj_dir', 'sin_adj_o', 'cos_adj_o', \\\n",
    "'sin_adj_dir', 'cos_adj_dir', 'dist_from_ball_carrier', 'min_teammate_dist', 'min_opponent_dist']\n",
    "'''\n",
    "\n",
    "data_df.loc[0,'state'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9526514",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "723edf01",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/amans/.local/lib/python3.9/site-packages/torch/cuda/__init__.py:52: UserWarning: CUDA initialization: CUDA unknown error - this may be due to an incorrectly set up environment, e.g. changing env variable CUDA_VISIBLE_DEVICES after program start. Setting the available devices to be zero. (Triggered internally at  ../c10/cuda/CUDAFunctions.cpp:115.)\n",
      "  return torch._C._cuda_getDeviceCount() > 0\n"
     ]
    }
   ],
   "source": [
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d8a40f9c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "size =  torch.Size([172245])\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "Create torch dataset\n",
    "'''\n",
    "\n",
    "features = torch.zeros(len(data_df)).to(device)\n",
    "labels = torch.zeros(len(data_df)).to(device)\n",
    "\n",
    "print(\"size = \", features.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "91376685",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['season', 'gameId', 'playId', 'playIndex', 'timeIndex', 'time',\n",
      "       'playerId', 'football_pos', 'state', 'next_state', 'reward', 'action',\n",
      "       'next_action'],\n",
      "      dtype='object')\n",
      "Length of training data: 120571\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "Function that splits the data into a training, validation, and test set\n",
    "'''\n",
    "def split_data(dataset, train_split, seed):\n",
    "    np.random.seed(seed)\n",
    "    indices = list(range(len(dataset)))\n",
    "    np.random.shuffle(indices)\n",
    "\n",
    "    train_num = int(len(dataset)*train_split)\n",
    "    val_num = (len(dataset) - int(len(dataset)*train_split))//2\n",
    "\n",
    "    train_indices = indices[0:train_num]\n",
    "    val_indices = indices[train_num:train_num+val_num]\n",
    "    test_indices = indices[train_num+val_num:]\n",
    "\n",
    "    #check to make sure slices correct\n",
    "    assert len(dataset) == len(train_indices) + len(val_indices) + len(test_indices)\n",
    "\n",
    "    #dataset = help.normalize(train_indices, dataset)\n",
    "\n",
    "    train_data = dataset.iloc[train_indices,:]\n",
    "    val_data = dataset.iloc[val_indices,:]\n",
    "    test_data = dataset.iloc[test_indices,:]\n",
    "\n",
    "    return train_data, val_data, test_data\n",
    "\n",
    "train_data, val_data, test_data = split_data(data_df, 0.7, 2430)\n",
    "\n",
    "print(test_data.columns)\n",
    "\n",
    "print(f\"Length of training data: {len(train_data)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "200b93b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "State size: 18\n",
      "Action size: 8\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'\\nFirst CNN model\\ncnn_model = nn.Sequential(\\n    nn.Conv2d(1, 12, (12,1), stride=1, padding=0),\\n    nn.LeakyReLU(),\\n    nn.Conv2d(12, 24, (6, 1)),\\n    nn.LeakyReLU(),\\n    nn.Conv2d(24, 48, (1,1)),\\n    nn.Flatten(),\\n    nn.Linear(48*6*6,action_size)\\n)\\n\\ncnn_model.to(device=device)\\n'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "Predict ['s', 'a', 'adj_x', 'adj_y', 'adj_o', 'adj_dir', 'sin_adj_o', 'cos_adj_o', 'sin_adj_dir', 'cos_adj_dir']\n",
    "from \n",
    "['x','y', 'dis', 's', 'a', 'o', 'dir', 'adj_x', 'adj_y', 'adj_o', 'adj_dir', 'sin_adj_o', 'cos_adj_o', \\\n",
    "'sin_adj_dir', 'cos_adj_dir', 'dist_from_ball_carrier', 'min_teammate_dist', 'min_opponent_dist']\n",
    "'''\n",
    "\n",
    "\n",
    "\n",
    "'''\n",
    "Define hyperparamters\n",
    "'''\n",
    "BATCH_SIZE = 64\n",
    "state_size = len(data_df.loc[0,'state'][0])\n",
    "action_size = 8\n",
    "gamma = 0.99\n",
    "#max_action = torch.tensor(max_action, dtype=torch.float32).to(device=device)\n",
    "\n",
    "print(f\"State size: {state_size}\")\n",
    "print(f\"Action size: {action_size}\")\n",
    "    \n",
    "'''\n",
    "First CNN model\n",
    "cnn_model = nn.Sequential(\n",
    "    nn.Conv2d(1, 12, (12,1), stride=1, padding=0),\n",
    "    nn.LeakyReLU(),\n",
    "    nn.Conv2d(12, 24, (6, 1)),\n",
    "    nn.LeakyReLU(),\n",
    "    nn.Conv2d(24, 48, (1,1)),\n",
    "    nn.Flatten(),\n",
    "    nn.Linear(48*6*6,action_size)\n",
    ")\n",
    "\n",
    "cnn_model.to(device=device)\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9839d87d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# lowest val loss for this model was .34. Then starter going up (e.g. ~.88)\n",
    "cnn_model = nn.Sequential(\n",
    "    nn.Conv2d(1, 32, (3,3), stride=1,padding=0),\n",
    "    nn.LeakyReLU(),\n",
    "    #nn.MaxPool2d((2,2), stride=2),\n",
    "    nn.Conv2d(32, 64, (3,3), stride=1,padding=0),\n",
    "    nn.LeakyReLU(),\n",
    "    #nn.MaxPool2d((2,2), stride=2),\n",
    "    nn.Conv2d(64,128, (2,2), stride=1,padding=0),\n",
    "    nn.LeakyReLU(),\n",
    "    #nn.MaxPool2d((2,2), stride=2),\n",
    "    nn.Conv2d(128,256, (1,1), stride=1,padding=0),\n",
    "    nn.LeakyReLU(),\n",
    "    #nn.MaxPool2d((2,2), stride=2),\n",
    "    #nn.Conv2d(256,512, (3,3), stride=1,padding=0),\n",
    "    #nn.LeakyReLU(),\n",
    "    #nn.MaxPool2d((2,2), stride=2),\n",
    "    nn.Flatten(),\n",
    "    nn.Linear(13824, 6000),\n",
    "    nn.LeakyReLU(),\n",
    "    nn.Linear(6000, 2000),\n",
    "    nn.LeakyReLU(),\n",
    "    nn.Linear(2000, 500),\n",
    "    nn.LeakyReLU(),\n",
    "    nn.Linear(500, 100),\n",
    "    nn.LeakyReLU(),\n",
    "    nn.Linear(100, action_size)\n",
    ")\n",
    "\n",
    "\n",
    "# small teammate model ~ 0.3046 val accuracy after 4 epochs, batch=64\n",
    "# cnn_model = nn.Sequential(\n",
    "#     nn.Conv2d(1, 6, (2,2), stride=1, padding=0),\n",
    "#     nn.Flatten(),\n",
    "#     nn.Linear(924,300), \n",
    "#     nn.LeakyReLU(),\n",
    "#     nn.Linear(300,100), \n",
    "#     nn.LeakyReLU(),\n",
    "#     nn.Linear(100,action_size)\n",
    "# )\n",
    "\n",
    "\n",
    "'''\n",
    "cnn_model = nn.Sequential(\n",
    "    nn.Flatten(),\n",
    "    nn.Linear(176,100), \n",
    "    nn.LeakyReLU(),\n",
    "    nn.Linear(100,50), \n",
    "    nn.LeakyReLU(),\n",
    "    nn.Linear(50,action_size)\n",
    ")\n",
    "\n",
    "cnn_model = nn.Sequential(\n",
    "    nn.Flatten(),\n",
    "    nn.Linear(176,60), \n",
    "    nn.Dropout(p=0.5),\n",
    "    nn.LeakyReLU(),\n",
    "    nn.Linear(60,action_size)\n",
    ")\n",
    "'''\n",
    "\n",
    "\n",
    "cnn_model.to(device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b895e4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define loss function\n",
    "mse_loss_fn = nn.MSELoss()\n",
    "# define optimizers\n",
    "cnn_optimizer = optim.Adam(cnn_model.parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2525795f",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.stack(test_data.iloc[0,:]['action'])[0,1:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9af9954e",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Given indices, train model on batch\n",
    "['x','y', 'dis', 's', 'a', 'o', 'dir', 'adj_x', 'adj_y', 'adj_o', 'adj_dir', 'sin_adj_o', 'cos_adj_o', \\\n",
    "'sin_adj_dir', 'cos_adj_dir', 'dist_from_ball_carrier', 'min_teammate_dist', 'min_opponent_dist']\n",
    "'''\n",
    "def train_loop(df, indices, model, loss_fn, optimizer, device):\n",
    "    size = len(indices)\n",
    "    play = df.iloc[indices, :]\n",
    "    \n",
    "    numpy_state = np.stack(play['state'].values)\n",
    "    batch_size = numpy_state.shape[0]\n",
    "    numpy_state_input = numpy_state.reshape(batch_size, 1, -1, state_size)[:,:,:,[3,4,7,8,11,12,13,14]]\n",
    "    \n",
    "    true_state = torch.tensor(numpy_state, dtype=torch.float32).to(device=device)\n",
    "    true_action = torch.tensor(np.stack(play['action'].values)[:,0,[3,4,7,8,11,12,13,14]], dtype=torch.float32).to(device=device)\n",
    "    \n",
    "    # shape true state into matrix to pass into CNN\n",
    "    #true_state_mod = true_state.reshape(batch_size, -1, len(true_action))\n",
    "    true_state_mod = torch.tensor(numpy_state_input, dtype=torch.float32).to(device=device)\n",
    "\n",
    "    model.train()  # put model to training mode\n",
    "\n",
    "    #compute prediction and loss\n",
    "    predicted_action = model(true_state_mod)\n",
    "    \n",
    "    loss = loss_fn(predicted_action, true_action)\n",
    "\n",
    "    #Backpropagation\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    \n",
    "    return loss/size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afcb7c95",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_loop(test_df, model, loss_fn, device):\n",
    "    size = len(test_df)\n",
    "    test_loss = 0\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for row_index in range(0,len(test_df)):\n",
    "\n",
    "            play = test_df.iloc[row_index, :]\n",
    "\n",
    "            true_state = torch.tensor(play['state'], dtype=torch.float32).to(device=device)\n",
    "            true_action = torch.tensor(play['action'][0,[3,4,7,8,11,12,13,14]], dtype=torch.float32).to(device=device)\n",
    "            \n",
    "            # useful for if testing in batches\n",
    "            #true_state = torch.tensor(np.stack(play['state'].values), dtype=torch.float32).to(device=device)\n",
    "            #true_action = torch.tensor(np.stack(play['action'].values), dtype=torch.float32).to(device=device)\n",
    "\n",
    "            numpy_state_input = play['state'].reshape(1, 1, -1, state_size)[:,:,:,[3,4,7,8,11,12,13,14]]\n",
    "                           \n",
    "            true_state_mod = torch.tensor(numpy_state_input, dtype=torch.float32).to(device=device)\n",
    "\n",
    "            model.eval()  # put model to eval mode\n",
    "\n",
    "            #compute prediction and loss\n",
    "            predicted_action = model(true_state_mod)\n",
    "  \n",
    "            true_action = torch.unsqueeze(true_action, 0)\n",
    "\n",
    "            loss = loss_fn(predicted_action, true_action)\n",
    "            \n",
    "            test_loss += loss\n",
    "        \n",
    "        test_loss = test_loss/size\n",
    "\n",
    "    \n",
    "    return test_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8db3d9bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "epochs = 4\n",
    "break_var = False\n",
    "training_loss_list = []\n",
    "val_loss_list = []\n",
    "\n",
    "num_batches = int(len(train_data)/BATCH_SIZE)+1\n",
    "\n",
    "print(f\"Num batches: {num_batches}\")\n",
    "\n",
    "indexes = list(range(0,len(train_data)))\n",
    "\n",
    "np.random.seed(2430)\n",
    "\n",
    "for k in range(epochs):\n",
    "    \n",
    "    random.shuffle(indexes)\n",
    "    \n",
    "    for i in range(num_batches):\n",
    "\n",
    "        start_index = i*BATCH_SIZE\n",
    "        end_index = min(len(train_data), (i+1)*BATCH_SIZE)\n",
    "        \n",
    "        #indices = list(range(start_index, end_index))\n",
    "        indices = indexes[start_index:end_index]\n",
    "\n",
    "        train_loss = train_loop(train_data, indices, cnn_model, mse_loss_fn, cnn_optimizer, device)\n",
    "        \n",
    "        training_loss_list.append(train_loss)\n",
    "\n",
    "        if (i % int(num_batches/2) == 0):# and (i != 0):\n",
    "            val_loss = test_loop(val_data, cnn_model, F.mse_loss, device)\n",
    "            val_loss_list.append(val_loss)\n",
    "            print(f\"At epoch {k}, iter {i}: train loss = {train_loss}\")\n",
    "            print(f\"At epoch {k}, iter {i}: val loss = {val_loss}\")\n",
    "            \n",
    "torch.save(cnn_model.state_dict(), 'teammate_model_large.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c950c557",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e408d950",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Try model predicting entire sequence\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "97ca561e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "cnnModel(\n",
       "  (batch_norm): BatchNorm1d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (conv1): Conv2d(1, 32, kernel_size=(8, 8), stride=(1, 1))\n",
       "  (flatten): Flatten(start_dim=1, end_dim=-1)\n",
       "  (linear1): Linear(in_features=512, out_features=230, bias=True)\n",
       "  (leaky): LeakyReLU(negative_slope=0.01)\n",
       "  (linear2): Linear(in_features=230, out_features=184, bias=True)\n",
       "  (drop): Dropout(p=0.5, inplace=False)\n",
       ")"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "same results, not great val loss and then overfit\n",
    "'''\n",
    "# cnn_model = nn.Sequential(\n",
    "#     nn.Conv2d(1, 32, (3,3), stride=1,padding=0),\n",
    "#     nn.LeakyReLU(),\n",
    "#     #nn.MaxPool2d((2,2), stride=2),\n",
    "#     nn.Conv2d(32, 64, (3,3), stride=1,padding=0),\n",
    "#     nn.LeakyReLU(),\n",
    "#     #nn.MaxPool2d((2,2), stride=2),\n",
    "#     nn.Conv2d(64,128, (2,2), stride=1,padding=0),\n",
    "#     nn.LeakyReLU(),\n",
    "#     #nn.MaxPool2d((2,2), stride=2),\n",
    "#     nn.Conv2d(128,256, (1,1), stride=1,padding=0),\n",
    "#     nn.LeakyReLU(),\n",
    "#     #nn.MaxPool2d((2,2), stride=2),\n",
    "#     #nn.Conv2d(256,512, (3,3), stride=1,padding=0),\n",
    "#     #nn.LeakyReLU(),\n",
    "#     #nn.MaxPool2d((2,2), stride=2),\n",
    "#     nn.Flatten(),\n",
    "#     nn.Linear(13824, 6000),\n",
    "#     nn.LeakyReLU(),\n",
    "#     nn.Linear(6000, 2000),\n",
    "#     nn.LeakyReLU(),\n",
    "#     nn.Linear(2000, 500),\n",
    "#     nn.LeakyReLU(),\n",
    "#     nn.Linear(500, action_size*23)\n",
    "# )\n",
    "\n",
    "'''\n",
    "val loss @ .3 after 4 epochs, .287 after 7 epochs, .286 after 8 epochs\n",
    "'''\n",
    "# cnn_model = nn.Sequential(\n",
    "#     nn.Conv2d(1, 6, (2,2), stride=1, padding=0),\n",
    "#     nn.Flatten(),\n",
    "#     nn.Linear(924,400), \n",
    "#     nn.LeakyReLU(),\n",
    "#     nn.Linear(400,action_size*23)\n",
    "# )\n",
    "\n",
    "'''\n",
    "Similar val losses. .359 val loss after 3 epochs, .313 after 4\n",
    "'''\n",
    "# cnn_model = nn.Sequential(\n",
    "#     nn.Conv2d(1, 3, (2,2), stride=1, padding=0),\n",
    "#     nn.Flatten(),\n",
    "#     nn.Linear(462,230), \n",
    "#     nn.LeakyReLU(),\n",
    "#     nn.Linear(230,action_size*23)\n",
    "# )\n",
    "\n",
    "'''\n",
    "Similar val losses, .283 val loss after 2 epochs, .281 after 4\n",
    "'''\n",
    "# cnn_model = nn.Sequential(\n",
    "#     nn.BatchNorm2d(1),\n",
    "#     nn.Conv2d(1, 32, (8,8), stride=1, padding=0),\n",
    "#     nn.Flatten(),\n",
    "#     nn.Linear(128*4,230), \n",
    "#     nn.LeakyReLU(),\n",
    "#     nn.Linear(230,action_size*23)\n",
    "# )\n",
    "\n",
    "class cnnModel(nn.Module):\n",
    "    def __init__(self, action_size):\n",
    "        super(cnnModel, self).__init__()\n",
    "        \n",
    "        self.action_size = action_size\n",
    "        \n",
    "        self.batch_norm = nn.BatchNorm1d(8)\n",
    "        self.conv1 = nn.Conv2d(1, 32, (8,8), stride=1, padding=0)\n",
    "        self.flatten = nn.Flatten()\n",
    "        self.linear1 = nn.Linear(128*4,230)\n",
    "        self.leaky = nn.LeakyReLU()\n",
    "        self.linear2 = nn.Linear(230,action_size*23)\n",
    "        \n",
    "        self.drop = nn.Dropout(.5)\n",
    "        \n",
    "    # input (batch_size, 1, 23, action_size)\n",
    "    def forward(self, input_tensor):\n",
    "        \n",
    "        #tens_reshape = input_tensor.view(-1, 23, 8)\n",
    "        initial_shape = input_tensor.shape\n",
    "        \n",
    "        batched_input = self.batch_norm(torch.transpose(input_tensor.view(-1, 23, 8), 1,2))\n",
    "        \n",
    "        inp = torch.transpose(batched_input, 1, 2).view(initial_shape)\n",
    "        \n",
    "        output = self.conv1(inp)\n",
    "        output = self.flatten(output)\n",
    "        output = self.drop(output)\n",
    "        output = self.linear1(output)\n",
    "        output = self.leaky(output)\n",
    "        output = self.linear2(output)\n",
    "        \n",
    "        return output\n",
    "cnn_model = cnnModel(action_size)\n",
    "\n",
    "cnn_model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "90e4f937",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.optim.lr_scheduler import LambdaLR\n",
    "from torch.optim.lr_scheduler import ExponentialLR\n",
    "\n",
    "# define loss function\n",
    "mse_loss_fn = nn.MSELoss()\n",
    "#mse_loss_fn = nn.L1Loss()\n",
    "# define optimizers\n",
    "cnn_optimizer = optim.Adam(cnn_model.parameters(), lr=0.005)\n",
    "\n",
    "#scheduler = ExponentialLR(cnn_optimizer, gamma=0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "5cce47a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Given indices, train model on batch\n",
    "['x','y', 'dis', 's', 'a', 'o', 'dir', 'adj_x', 'adj_y', 'adj_o', 'adj_dir', 'sin_adj_o', 'cos_adj_o', \\\n",
    "'sin_adj_dir', 'cos_adj_dir', 'dist_from_ball_carrier', 'min_teammate_dist', 'min_opponent_dist']\n",
    "'''\n",
    "def train_loop_large(df, indices, model, loss_fn, optimizer, device):\n",
    "    size = len(indices)\n",
    "    play = df.iloc[indices, :]\n",
    "    \n",
    "    numpy_state = np.stack(play['state'].values)\n",
    "    batch_size = numpy_state.shape[0]\n",
    "    numpy_state_input = numpy_state.reshape(batch_size, 1, -1, state_size)[:,:,:,[3,4,7,8,11,12,13,14]]\n",
    "    \n",
    "    true_state = torch.tensor(numpy_state, dtype=torch.float32).to(device=device)\n",
    "    true_action = torch.tensor(np.stack(play['action'].values)[:,:,[3,4,7,8,11,12,13,14]].reshape(batch_size, -1), dtype=torch.float32).to(device=device)\n",
    "    \n",
    "    # shape true state into matrix to pass into CNN\n",
    "    true_state_mod = torch.tensor(numpy_state_input, dtype=torch.float32).to(device=device)\n",
    "\n",
    "    model.train()  # put model to training mode\n",
    "\n",
    "    #compute prediction and loss\n",
    "    predicted_action = model(true_state_mod)\n",
    "    \n",
    "    loss = loss_fn(predicted_action, true_action)\n",
    "\n",
    "    #Backpropagation\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    \n",
    "    return loss/size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "80c3d5b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_loop_large(test_df, model, loss_fn, device):\n",
    "    size = len(test_df)\n",
    "    test_loss = 0\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for row_index in range(0,len(test_df)):\n",
    "\n",
    "            play = test_df.iloc[row_index, :]\n",
    "\n",
    "            true_state = torch.tensor(play['state'], dtype=torch.float32).to(device=device)\n",
    "            true_action = torch.tensor(play['action'][:,[3,4,7,8,11,12,13,14]].reshape(-1), dtype=torch.float32).to(device=device)\n",
    "            \n",
    "            # useful for if testing in batches\n",
    "            #true_state = torch.tensor(np.stack(play['state'].values), dtype=torch.float32).to(device=device)\n",
    "            #true_action = torch.tensor(np.stack(play['action'].values), dtype=torch.float32).to(device=device)\n",
    "\n",
    "            numpy_state_input = play['state'].reshape(1, 1, -1, state_size)[:,:,:,[3,4,7,8,11,12,13,14]]\n",
    "                           \n",
    "            true_state_mod = torch.tensor(numpy_state_input, dtype=torch.float32).to(device=device)\n",
    "\n",
    "            model.eval()  # put model to eval mode\n",
    "\n",
    "            #compute prediction and loss\n",
    "            predicted_action = model(true_state_mod)\n",
    "  \n",
    "            true_action = torch.unsqueeze(true_action, 0)\n",
    "\n",
    "            loss = loss_fn(predicted_action, true_action)\n",
    "            \n",
    "            test_loss += loss\n",
    "        \n",
    "        test_loss = test_loss/size\n",
    "\n",
    "    \n",
    "    return test_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "134032b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num batches: 1884\n",
      "At epoch 0, iter 0: train loss = 0.008427238091826439\n",
      "At epoch 0, iter 0: val loss = 0.6580563187599182\n",
      "At epoch 0, iter 942: train loss = 0.005429424811154604\n",
      "At epoch 0, iter 942: val loss = 0.30924633145332336\n",
      "post scheduler step lr =  0.0005\n",
      "At epoch 1, iter 0: train loss = 0.005247880704700947\n",
      "At epoch 1, iter 0: val loss = 0.3010599911212921\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_24453/3235017732.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     35\u001b[0m                 \u001b[0;31m#print(g['lr'])\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 37\u001b[0;31m             \u001b[0mval_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtest_loop_large\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mval_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcnn_model\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmse_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     38\u001b[0m             \u001b[0mval_loss_list\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mval_loss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"At epoch {k}, iter {i}: train loss = {train_loss}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_24453/1180396600.py\u001b[0m in \u001b[0;36mtest_loop_large\u001b[0;34m(test_df, model, loss_fn, device)\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m             \u001b[0;31m#compute prediction and loss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 24\u001b[0;31m             \u001b[0mpredicted_action\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrue_state_mod\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     25\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m             \u001b[0mtrue_action\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munsqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrue_action\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.9/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1049\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1050\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1051\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1052\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1053\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_24453/2269922860.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_tensor)\u001b[0m\n\u001b[1;32m     92\u001b[0m         \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinear1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m         \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mleaky\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 94\u001b[0;31m         \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinear2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     95\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     96\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0moutput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.9/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1049\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1050\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1051\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1052\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1053\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.9/site-packages/torch/nn/modules/linear.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m     94\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     95\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 96\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     97\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     98\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mextra_repr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.9/site-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36mlinear\u001b[0;34m(input, weight, bias)\u001b[0m\n\u001b[1;32m   1845\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhas_torch_function_variadic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1846\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mhandle_torch_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlinear\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbias\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1847\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_nn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1848\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1849\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import random\n",
    "\n",
    "epochs = 8\n",
    "break_var = False\n",
    "training_loss_list = []\n",
    "val_loss_list = []\n",
    "\n",
    "num_batches = int(len(train_data)/BATCH_SIZE)+1\n",
    "\n",
    "print(f\"Num batches: {num_batches}\")\n",
    "\n",
    "indexes = list(range(0,len(train_data)))\n",
    "\n",
    "np.random.seed(2430)\n",
    "\n",
    "for k in range(epochs):\n",
    "    \n",
    "    random.shuffle(indexes)\n",
    "    \n",
    "    for i in range(num_batches):\n",
    "\n",
    "        start_index = i*BATCH_SIZE\n",
    "        end_index = min(len(train_data), (i+1)*BATCH_SIZE)\n",
    "        \n",
    "        #indices = list(range(start_index, end_index))\n",
    "        indices = indexes[start_index:end_index]\n",
    "\n",
    "        train_loss = train_loop_large(train_data, indices, cnn_model, mse_loss_fn, cnn_optimizer, device)\n",
    "        \n",
    "        training_loss_list.append(train_loss)\n",
    "\n",
    "        if (i % int(num_batches/2) == 0):# and (i != 0):\n",
    "            #for g in cnn_optimizer.param_groups:\n",
    "                #g['lr'] = 0.001\n",
    "                #print(g['lr'])\n",
    "\n",
    "            val_loss = test_loop_large(val_data, cnn_model, F.mse_loss, device)\n",
    "            val_loss_list.append(val_loss)\n",
    "            print(f\"At epoch {k}, iter {i}: train loss = {train_loss}\")\n",
    "            print(f\"At epoch {k}, iter {i}: val loss = {val_loss}\")\n",
    "            \n",
    "    for g in cnn_optimizer.param_groups:\n",
    "        #g['lr'] = 0.001\n",
    "        g['lr'] /= 10\n",
    "        print('post scheduler step lr = ', g['lr'])\n",
    "    \n",
    "    #scheduler.step()\n",
    "            \n",
    "torch.save(cnn_model.state_dict(), 'all_model_large.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f6a8913",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
