{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "81c17a19",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import json\n",
    "import pickle\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "import torch.utils.data\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2378d714",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>season</th>\n",
       "      <th>gameId</th>\n",
       "      <th>playId</th>\n",
       "      <th>playIndex</th>\n",
       "      <th>timeIndex</th>\n",
       "      <th>time</th>\n",
       "      <th>football_pos</th>\n",
       "      <th>state</th>\n",
       "      <th>next_state</th>\n",
       "      <th>reward</th>\n",
       "      <th>action</th>\n",
       "      <th>next_action</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2018</td>\n",
       "      <td>2018090600</td>\n",
       "      <td>677</td>\n",
       "      <td>0</td>\n",
       "      <td>48</td>\n",
       "      <td>2018-09-07T01:34:34.100</td>\n",
       "      <td>[[12.42, 42.51, 6.89, 7.5, 0.0, 0.0]]</td>\n",
       "      <td>[[11.4, 42.67, 0.2, 3.07, 102.1, 312.17, 88.6,...</td>\n",
       "      <td>[[11.39, 42.66, 0.21, 2.84, 105.48, 199.45, 88...</td>\n",
       "      <td>-0.01</td>\n",
       "      <td>[0.01, 0.01, -0.01, 0.23, -3.38, 112.72, -0.01...</td>\n",
       "      <td>[-0.02, 0.03, -0.26, 0.31, -8.38, 31.09, 0.02,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2018</td>\n",
       "      <td>2018090600</td>\n",
       "      <td>677</td>\n",
       "      <td>0</td>\n",
       "      <td>49</td>\n",
       "      <td>2018-09-07T01:34:34.200</td>\n",
       "      <td>[[11.58, 42.54, 6.16, 6.87, 0.0, 0.0]]</td>\n",
       "      <td>[[11.39, 42.66, 0.21, 2.84, 105.48, 199.45, 88...</td>\n",
       "      <td>[[11.41, 42.63, 0.47, 2.53, 113.86, 168.36, 88...</td>\n",
       "      <td>0.02</td>\n",
       "      <td>[-0.02, 0.03, -0.26, 0.31, -8.38, 31.09, 0.02,...</td>\n",
       "      <td>[-0.04, 0.07, -0.36, 0.0, 3.17, 10.04, 0.04, 0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2018</td>\n",
       "      <td>2018090600</td>\n",
       "      <td>677</td>\n",
       "      <td>0</td>\n",
       "      <td>50</td>\n",
       "      <td>2018-09-07T01:34:34.300</td>\n",
       "      <td>[[11.3, 42.45, 4.94, 7.15, 0.0, 0.0]]</td>\n",
       "      <td>[[11.41, 42.63, 0.47, 2.53, 113.86, 168.36, 88...</td>\n",
       "      <td>[[11.45, 42.56, 0.83, 2.53, 110.69, 158.32, 88...</td>\n",
       "      <td>0.04</td>\n",
       "      <td>[-0.04, 0.07, -0.36, 0.0, 3.17, 10.04, 0.04, 0...</td>\n",
       "      <td>[-0.08, 0.11, -0.49, -0.5, -6.61, 10.26, 0.08,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2018</td>\n",
       "      <td>2018090600</td>\n",
       "      <td>677</td>\n",
       "      <td>0</td>\n",
       "      <td>51</td>\n",
       "      <td>2018-09-07T01:34:34.400</td>\n",
       "      <td>[[11.32, 42.34, 3.78, 7.54, 0.0, 0.0]]</td>\n",
       "      <td>[[11.45, 42.56, 0.83, 2.53, 110.69, 158.32, 88...</td>\n",
       "      <td>[[11.53, 42.45, 1.32, 3.03, 117.3, 148.06, 88....</td>\n",
       "      <td>0.08</td>\n",
       "      <td>[-0.08, 0.11, -0.49, -0.5, -6.61, 10.26, 0.08,...</td>\n",
       "      <td>[-0.09, 0.13, -0.38, -0.1, 2.88, 3.22, 0.09, 0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2018</td>\n",
       "      <td>2018090600</td>\n",
       "      <td>677</td>\n",
       "      <td>0</td>\n",
       "      <td>52</td>\n",
       "      <td>2018-09-07T01:34:34.500</td>\n",
       "      <td>[[11.15, 42.28, 2.91, 6.78, 0.0, 0.0]]</td>\n",
       "      <td>[[11.53, 42.45, 1.32, 3.03, 117.3, 148.06, 88....</td>\n",
       "      <td>[[11.62, 42.32, 1.7, 3.13, 114.42, 144.84, 88....</td>\n",
       "      <td>0.09</td>\n",
       "      <td>[-0.09, 0.13, -0.38, -0.1, 2.88, 3.22, 0.09, 0...</td>\n",
       "      <td>[-0.16, 0.16, -0.53, -0.24, -17.77, 7.48, 0.16...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  season      gameId  playId  playIndex  timeIndex                     time  \\\n",
       "0   2018  2018090600     677          0         48  2018-09-07T01:34:34.100   \n",
       "1   2018  2018090600     677          0         49  2018-09-07T01:34:34.200   \n",
       "2   2018  2018090600     677          0         50  2018-09-07T01:34:34.300   \n",
       "3   2018  2018090600     677          0         51  2018-09-07T01:34:34.400   \n",
       "4   2018  2018090600     677          0         52  2018-09-07T01:34:34.500   \n",
       "\n",
       "                             football_pos  \\\n",
       "0   [[12.42, 42.51, 6.89, 7.5, 0.0, 0.0]]   \n",
       "1  [[11.58, 42.54, 6.16, 6.87, 0.0, 0.0]]   \n",
       "2   [[11.3, 42.45, 4.94, 7.15, 0.0, 0.0]]   \n",
       "3  [[11.32, 42.34, 3.78, 7.54, 0.0, 0.0]]   \n",
       "4  [[11.15, 42.28, 2.91, 6.78, 0.0, 0.0]]   \n",
       "\n",
       "                                               state  \\\n",
       "0  [[11.4, 42.67, 0.2, 3.07, 102.1, 312.17, 88.6,...   \n",
       "1  [[11.39, 42.66, 0.21, 2.84, 105.48, 199.45, 88...   \n",
       "2  [[11.41, 42.63, 0.47, 2.53, 113.86, 168.36, 88...   \n",
       "3  [[11.45, 42.56, 0.83, 2.53, 110.69, 158.32, 88...   \n",
       "4  [[11.53, 42.45, 1.32, 3.03, 117.3, 148.06, 88....   \n",
       "\n",
       "                                          next_state  reward  \\\n",
       "0  [[11.39, 42.66, 0.21, 2.84, 105.48, 199.45, 88...   -0.01   \n",
       "1  [[11.41, 42.63, 0.47, 2.53, 113.86, 168.36, 88...    0.02   \n",
       "2  [[11.45, 42.56, 0.83, 2.53, 110.69, 158.32, 88...    0.04   \n",
       "3  [[11.53, 42.45, 1.32, 3.03, 117.3, 148.06, 88....    0.08   \n",
       "4  [[11.62, 42.32, 1.7, 3.13, 114.42, 144.84, 88....    0.09   \n",
       "\n",
       "                                              action  \\\n",
       "0  [0.01, 0.01, -0.01, 0.23, -3.38, 112.72, -0.01...   \n",
       "1  [-0.02, 0.03, -0.26, 0.31, -8.38, 31.09, 0.02,...   \n",
       "2  [-0.04, 0.07, -0.36, 0.0, 3.17, 10.04, 0.04, 0...   \n",
       "3  [-0.08, 0.11, -0.49, -0.5, -6.61, 10.26, 0.08,...   \n",
       "4  [-0.09, 0.13, -0.38, -0.1, 2.88, 3.22, 0.09, 0...   \n",
       "\n",
       "                                         next_action  \n",
       "0  [-0.02, 0.03, -0.26, 0.31, -8.38, 31.09, 0.02,...  \n",
       "1  [-0.04, 0.07, -0.36, 0.0, 3.17, 10.04, 0.04, 0...  \n",
       "2  [-0.08, 0.11, -0.49, -0.5, -6.61, 10.26, 0.08,...  \n",
       "3  [-0.09, 0.13, -0.38, -0.1, 2.88, 3.22, 0.09, 0...  \n",
       "4  [-0.16, 0.16, -0.53, -0.24, -17.77, 7.48, 0.16...  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "Read in saved dataset to use to feed into the model.\n",
    "Further pre-processing still needs to be done on the state vectors\n",
    "'''\n",
    "\n",
    "data_df = pd.read_pickle('/home/amans/Development/scott/nfl-big-data-bowl-2022/clean_dir/from_csv.pkl')\n",
    "\n",
    "data_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "723edf01",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/amans/.local/lib/python3.9/site-packages/torch/cuda/__init__.py:52: UserWarning: CUDA initialization: CUDA unknown error - this may be due to an incorrectly set up environment, e.g. changing env variable CUDA_VISIBLE_DEVICES after program start. Setting the available devices to be zero. (Triggered internally at  ../c10/cuda/CUDAFunctions.cpp:115.)\n",
      "  return torch._C._cuda_getDeviceCount() > 0\n"
     ]
    }
   ],
   "source": [
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d8a40f9c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "size =  torch.Size([209239])\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "Create torch dataset\n",
    "'''\n",
    "\n",
    "features = torch.zeros(len(data_df)).to(device)\n",
    "labels = torch.zeros(len(data_df)).to(device)\n",
    "\n",
    "print(\"size = \", features.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "91376685",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['season', 'gameId', 'playId', 'playIndex', 'timeIndex', 'time',\n",
      "       'football_pos', 'state', 'next_state', 'reward', 'action',\n",
      "       'next_action'],\n",
      "      dtype='object')\n",
      "Length of training data: 146467\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "Function that splits the data into a training, validation, and test set\n",
    "'''\n",
    "def split_data(dataset, train_split, seed):\n",
    "    np.random.seed(seed)\n",
    "    indices = list(range(len(dataset)))\n",
    "    np.random.shuffle(indices)\n",
    "\n",
    "    train_num = int(len(dataset)*train_split)\n",
    "    val_num = (len(dataset) - int(len(dataset)*train_split))//2\n",
    "\n",
    "    train_indices = indices[0:train_num]\n",
    "    val_indices = indices[train_num:train_num+val_num]\n",
    "    test_indices = indices[train_num+val_num:]\n",
    "\n",
    "    #check to make sure slices correct\n",
    "    assert len(dataset) == len(train_indices) + len(val_indices) + len(test_indices)\n",
    "\n",
    "    #dataset = help.normalize(train_indices, dataset)\n",
    "\n",
    "    train_data = dataset.iloc[train_indices,:]\n",
    "    val_data = dataset.iloc[val_indices,:]\n",
    "    test_data = dataset.iloc[test_indices,:]\n",
    "\n",
    "    return train_data, val_data, test_data\n",
    "\n",
    "train_data, val_data, test_data = split_data(data_df, 0.7, 2430)\n",
    "\n",
    "print(test_data.columns)\n",
    "\n",
    "print(f\"Length of training data: {len(train_data)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "200b93b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "State size: 22\n",
      "Action size: 4\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'\\nFirst CNN model\\ncnn_model = nn.Sequential(\\n    nn.Conv2d(1, 12, (12,1), stride=1, padding=0),\\n    nn.LeakyReLU(),\\n    nn.Conv2d(12, 24, (6, 1)),\\n    nn.LeakyReLU(),\\n    nn.Conv2d(24, 48, (1,1)),\\n    nn.Flatten(),\\n    nn.Linear(48*6*6,action_size)\\n)\\n\\ncnn_model.to(device=device)\\n'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "Define models\n",
    "'''\n",
    "\n",
    "'''\n",
    "Define hyperparamters\n",
    "'''\n",
    "BATCH_SIZE = 128\n",
    "state_size = len(data_df.loc[0,'state'])\n",
    "action_size = 4\n",
    "gamma = 0.99\n",
    "#max_action = torch.tensor(max_action, dtype=torch.float32).to(device=device)\n",
    "\n",
    "print(f\"State size: {state_size}\")\n",
    "print(f\"Action size: {action_size}\")\n",
    "    \n",
    "'''\n",
    "First CNN model\n",
    "cnn_model = nn.Sequential(\n",
    "    nn.Conv2d(1, 12, (12,1), stride=1, padding=0),\n",
    "    nn.LeakyReLU(),\n",
    "    nn.Conv2d(12, 24, (6, 1)),\n",
    "    nn.LeakyReLU(),\n",
    "    nn.Conv2d(24, 48, (1,1)),\n",
    "    nn.Flatten(),\n",
    "    nn.Linear(48*6*6,action_size)\n",
    ")\n",
    "\n",
    "cnn_model.to(device=device)\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9839d87d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sequential(\n",
       "  (0): Flatten(start_dim=1, end_dim=-1)\n",
       "  (1): Linear(in_features=88, out_features=50, bias=True)\n",
       "  (2): LeakyReLU(negative_slope=0.01)\n",
       "  (3): Linear(in_features=50, out_features=25, bias=True)\n",
       "  (4): LeakyReLU(negative_slope=0.01)\n",
       "  (5): Linear(in_features=25, out_features=4, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "cnn_model = nn.Sequential(\n",
    "    nn.Conv2d(1, 32, (3,3), stride=1,padding=0),\n",
    "    nn.LeakyReLU(),\n",
    "    #nn.MaxPool2d((2,2), stride=2),\n",
    "    nn.Conv2d(32, 64, (3,3), stride=1,padding=0),\n",
    "    nn.LeakyReLU(),\n",
    "    #nn.MaxPool2d((2,2), stride=2),\n",
    "    nn.Conv2d(64,128, (2,2), stride=1,padding=0),\n",
    "    nn.LeakyReLU(),\n",
    "    #nn.MaxPool2d((2,2), stride=2),\n",
    "    nn.Conv2d(128,256, (1,1), stride=1,padding=0),\n",
    "    #nn.LeakyReLU(),\n",
    "    #nn.MaxPool2d((2,2), stride=2),\n",
    "    #nn.Conv2d(256,512, (3,3), stride=1,padding=0),\n",
    "    nn.LeakyReLU(),\n",
    "    #nn.MaxPool2d((2,2), stride=2),\n",
    "    nn.Flatten(),\n",
    "    nn.Linear(4352, 2000),\n",
    "    nn.LeakyReLU(),\n",
    "    nn.Linear(2000, 1000),\n",
    "    nn.LeakyReLU(),\n",
    "    nn.Linear(1000, 100),\n",
    "    nn.LeakyReLU(),\n",
    "    nn.Linear(100, action_size)\n",
    ")\n",
    "cnn_model.to(device=device)\n",
    "\n",
    "cnn_model = nn.Sequential(\n",
    "    nn.Conv2d(1, 4, (2,1), stride=1, padding=0),\n",
    "    nn.LeakyReLU(),\n",
    "    nn.Flatten(),\n",
    "    nn.Linear(504,200), \n",
    "    nn.LeakyReLU(),\n",
    "    nn.Linear(200,action_size)\n",
    ")\n",
    "\n",
    "cnn_model.to(device=device)\n",
    "'''\n",
    "\n",
    "cnn_model = nn.Sequential(\n",
    "    nn.Flatten(),\n",
    "    nn.Linear(88,50), \n",
    "    nn.LeakyReLU(),\n",
    "    nn.Linear(50,25),\n",
    "    nn.LeakyReLU(),\n",
    "    nn.Linear(25,action_size)\n",
    ")\n",
    "\n",
    "cnn_model.to(device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4b895e4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define loss function\n",
    "mse_loss_fn = nn.MSELoss()\n",
    "# define optimizers\n",
    "cnn_optimizer = optim.Adam(cnn_model.parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2525795f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[[0., 0., 0.],\n",
       "         [0., 0., 0.]]]])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "z = np.zeros((1,1,2,4))\n",
    "\n",
    "z[:,:,:,[0,2,3]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9af9954e",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Given indices, train model on batch\n",
    "'''\n",
    "def train_loop(df, indices, model, loss_fn, optimizer, device):\n",
    "    size = len(indices)\n",
    "    play = df.iloc[indices, :]\n",
    "    \n",
    "    numpy_state = np.stack(play['state'].values)\n",
    "    batch_size = numpy_state.shape[0]\n",
    "    numpy_state_input = numpy_state.reshape(batch_size, 1, -1, 8)[:,:,:,[2,3,6,7]]\n",
    "\n",
    "    true_state = torch.tensor(numpy_state, dtype=torch.float32).to(device=device)\n",
    "    true_action = torch.tensor(np.stack(play['action'].values)[:,[2,3,6,7]], dtype=torch.float32).to(device=device)\n",
    "    \n",
    "    # shape true state into matrix to pass into CNN\n",
    "    #true_state_mod = true_state.reshape(batch_size, -1, len(true_action))\n",
    "    true_state_mod = torch.tensor(numpy_state_input, dtype=torch.float32).to(device=device)\n",
    "\n",
    "    model.train()  # put model to training mode\n",
    "\n",
    "    #compute prediction and loss\n",
    "    predicted_action = model(true_state_mod)\n",
    "    \n",
    "    loss = loss_fn(predicted_action, true_action)\n",
    "\n",
    "    #Backpropagation\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    \n",
    "    return loss/size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "afcb7c95",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_loop(test_df, model, loss_fn, device):\n",
    "    size = len(test_df)\n",
    "    test_loss = 0\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for row_index in range(0,len(test_df)):\n",
    "\n",
    "            play = test_df.iloc[row_index, :]\n",
    "\n",
    "            true_state = torch.tensor(play['state'], dtype=torch.float32).to(device=device)\n",
    "            true_action = torch.tensor(play['action'][[2,3,6,7]], dtype=torch.float32).to(device=device)\n",
    "            \n",
    "            # useful for if testing in batches\n",
    "            #true_state = torch.tensor(np.stack(play['state'].values), dtype=torch.float32).to(device=device)\n",
    "            #true_action = torch.tensor(np.stack(play['action'].values), dtype=torch.float32).to(device=device)\n",
    "\n",
    "            numpy_state_input = play['state'].reshape(1, 1, -1, 8)[:,:,:,[2,3,6,7]]\n",
    "                           \n",
    "            true_state_mod = torch.tensor(numpy_state_input, dtype=torch.float32).to(device=device)\n",
    "\n",
    "            model.eval()  # put model to eval mode\n",
    "\n",
    "            #compute prediction and loss\n",
    "            predicted_action = model(true_state_mod)\n",
    "  \n",
    "            true_action = torch.unsqueeze(true_action, 0)\n",
    "            \n",
    "            loss = loss_fn(predicted_action, true_action)\n",
    "            \n",
    "            test_loss += loss\n",
    "        \n",
    "        test_loss = test_loss/size\n",
    "\n",
    "    \n",
    "    return test_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8db3d9bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num batches: 1145\n",
      "At epoch 0, iter 0: train loss = 0.059754058718681335\n",
      "At epoch 0, iter 0: val loss = 4.0469512939453125\n",
      "At epoch 0, iter 381: train loss = 0.0011124168522655964\n",
      "At epoch 0, iter 381: val loss = 0.12206614762544632\n",
      "At epoch 0, iter 762: train loss = 0.0009948015213012695\n",
      "At epoch 0, iter 762: val loss = 0.11457198858261108\n",
      "At epoch 0, iter 1143: train loss = 0.0008711127447895706\n",
      "At epoch 0, iter 1143: val loss = 0.10843068361282349\n",
      "At epoch 1, iter 0: train loss = 0.0009675890323705971\n",
      "At epoch 1, iter 0: val loss = 0.11415652930736542\n",
      "At epoch 1, iter 381: train loss = 0.000893519027158618\n",
      "At epoch 1, iter 381: val loss = 0.10634426027536392\n",
      "At epoch 1, iter 762: train loss = 0.0008622316527180374\n",
      "At epoch 1, iter 762: val loss = 0.10120908915996552\n",
      "At epoch 1, iter 1143: train loss = 0.0007408352103084326\n",
      "At epoch 1, iter 1143: val loss = 0.09907961636781693\n",
      "At epoch 2, iter 0: train loss = 0.0007659094990231097\n",
      "At epoch 2, iter 0: val loss = 0.10080092400312424\n",
      "At epoch 2, iter 381: train loss = 0.0008615512633696198\n",
      "At epoch 2, iter 381: val loss = 0.09839168936014175\n",
      "At epoch 2, iter 762: train loss = 0.0007341444143094122\n",
      "At epoch 2, iter 762: val loss = 0.0956905409693718\n",
      "At epoch 2, iter 1143: train loss = 0.0007612383924424648\n",
      "At epoch 2, iter 1143: val loss = 0.09557324647903442\n",
      "At epoch 3, iter 0: train loss = 0.0006450537475757301\n",
      "At epoch 3, iter 0: val loss = 0.09384790807962418\n",
      "At epoch 3, iter 381: train loss = 0.0007393280975520611\n",
      "At epoch 3, iter 381: val loss = 0.09314284473657608\n",
      "At epoch 3, iter 762: train loss = 0.0007721725269220769\n",
      "At epoch 3, iter 762: val loss = 0.09490220993757248\n",
      "At epoch 3, iter 1143: train loss = 0.000590374693274498\n",
      "At epoch 3, iter 1143: val loss = 0.09274259209632874\n",
      "At epoch 4, iter 0: train loss = 0.00070561608299613\n",
      "At epoch 4, iter 0: val loss = 0.09382788091897964\n",
      "At epoch 4, iter 381: train loss = 0.0007016822346486151\n",
      "At epoch 4, iter 381: val loss = 0.092557892203331\n",
      "At epoch 4, iter 762: train loss = 0.0009083117474801838\n",
      "At epoch 4, iter 762: val loss = 0.09200846403837204\n",
      "At epoch 4, iter 1143: train loss = 0.0008372366428375244\n",
      "At epoch 4, iter 1143: val loss = 0.09173484891653061\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "\n",
    "epochs = 5\n",
    "break_var = False\n",
    "training_loss_list = []\n",
    "val_loss_list = []\n",
    "\n",
    "num_batches = int(len(train_data)/BATCH_SIZE)+1\n",
    "\n",
    "print(f\"Num batches: {num_batches}\")\n",
    "\n",
    "indexes = list(range(0,len(train_data)))\n",
    "\n",
    "np.random.seed(2430)\n",
    "\n",
    "for k in range(epochs):\n",
    "    \n",
    "    random.shuffle(indexes)\n",
    "    \n",
    "    for i in range(num_batches):\n",
    "\n",
    "        start_index = i*BATCH_SIZE\n",
    "        end_index = min(len(train_data), (i+1)*BATCH_SIZE)\n",
    "        \n",
    "        #indices = list(range(start_index, end_index))\n",
    "        indices = indexes[start_index:end_index]\n",
    "\n",
    "        train_loss = train_loop(train_data, indices, cnn_model, mse_loss_fn, cnn_optimizer, device)\n",
    "        \n",
    "        training_loss_list.append(train_loss)\n",
    "\n",
    "        if (i % int(num_batches/3) == 0): #and (i != 0):\n",
    "            val_loss = test_loop(val_data, cnn_model, F.mse_loss, device)\n",
    "            val_loss_list.append(val_loss)\n",
    "            print(f\"At epoch {k}, iter {i}: train loss = {train_loss}\")\n",
    "            print(f\"At epoch {k}, iter {i}: val loss = {val_loss}\")\n",
    "            \n",
    "torch.save(cnn_model.state_dict(), 'cnn2.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c950c557",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cce47a0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80c3d5b2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "134032b2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
